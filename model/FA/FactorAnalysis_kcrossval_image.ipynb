{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (aesara.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import pymc as pm\n",
    "import aesara.tensor as at\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n",
    "import csv\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sys\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import extract_correct_csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "RANDOM_SEED = 31415\n",
    "rng = default_rng(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all valid subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subject = extract_correct_csv.extract_only_valid_subject()\n",
    "all_subject.remove(49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all k = {2, 4, 6, 8} for the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_k_list = list([2, 6, 10, 12, 15, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keep only generalization trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials_to_remove = 48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functions that creates triangular matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_packed_block_triangular(d, k, packed, diag=None, mtype=\"aesara\"):\n",
    "    # like expand_packed_triangular, but with d > k.\n",
    "    assert mtype in {\"aesara\", \"numpy\"}\n",
    "    assert d >= k\n",
    "    def set_(M, i_, v_):\n",
    "        if mtype == \"aesara\":\n",
    "            return at.set_subtensor(M[i_], v_)\n",
    "        M[i_] = v_\n",
    "        return M\n",
    "    out = at.zeros((d, k), dtype=float) if mtype == \"aesara\" else np.zeros((d, k), dtype=float)\n",
    "    if diag is None:\n",
    "        idxs = np.tril_indices(d, m=k)\n",
    "        out = set_(out, idxs, packed)\n",
    "    else:\n",
    "        idxs = np.tril_indices(d, k=-1, m=k)\n",
    "        out = set_(out, idxs, packed)\n",
    "        idxs = (np.arange(k), np.arange(k))\n",
    "        out = set_(out, idxs, diag)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeW(d, k, dim_names, name):\n",
    "    # make a W matrix adapted to the data shape\n",
    "    n_od = int(k * d - k * (k - 1) / 2 - k)\n",
    "    # trick: the cumulative sum of z will be positive increasing\n",
    "    z = pm.HalfNormal(\"W_z_\" + name, 1.0, dims=\"latent_columns\")\n",
    "    b = pm.HalfNormal(\"W_b_\" + name, 1.0, shape=(n_od,), dims=\"packed_dim\")\n",
    "    L = expand_packed_block_triangular(d, k, b, at.ones(k))\n",
    "    W = pm.Deterministic(name, at.dot(L, at.diag(at.extra_ops.cumsum(z))), dims=dim_names)\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_post_predict(trace, hr_new, eda_new, pupil_new, img_new):\n",
    "    whr_ = trace.posterior['W_hr'][0]\n",
    "    weda_ = trace.posterior['W_eda'][0]\n",
    "    wpupil_ = trace.posterior['W_pupil'][0]\n",
    "    wimg_ = trace.posterior['W_img'][0]\n",
    "    we_ = trace.posterior['W_e'][0]\n",
    "\n",
    "    C_val_hr = at.dot(np.linalg.pinv(whr_), hr_new.T)\n",
    "    C_val_eda = at.dot(np.linalg.pinv(weda_), eda_new.T)\n",
    "    C_val_pupil = at.dot(np.linalg.pinv(wpupil_), pupil_new.T)\n",
    "    C_val_img = at.dot(np.linalg.pinv(wimg_),img_new.T)\n",
    "\n",
    "    val_hr = at.matmul(np.array(we_), C_val_hr.eval())\n",
    "    val_eda = at.matmul(np.array(we_), C_val_eda.eval())\n",
    "    val_pupil = at.matmul(np.array(we_), C_val_pupil.eval())\n",
    "    val_img = at.matmul(np.array(wimg_),C_val_img.eval())\n",
    "\n",
    "    val_label_gen = at.concatenate((val_hr, val_eda, val_pupil, val_img))\n",
    "\n",
    "    label_val = np.where(val_label_gen.eval() < 0, 0, 1)\n",
    "    label_val = stats.mode(label_val[0], keepdims=False)[0]\n",
    "\n",
    "    return label_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME= 'output/FA/FA_kcv_norm_image.csv'\n",
    "columns = ['subject', 'k', 'fold', 'train', 'test']\n",
    "with open(FILENAME, 'w') as f:\n",
    "    write = csv.writer(f)\n",
    "    write.writerow(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "sub=2\n",
    "k=12"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda = pd.read_csv('data/features_4_2/eda/' + str(sub) + '.csv')\n",
    "eda = eda[num_trials_to_remove:]\n",
    "eda = scaler.fit_transform(eda)\n",
    "\n",
    "# hr data\n",
    "hr = pd.read_csv('data/features_4_2/hr/' + str(sub) + '.csv')\n",
    "hr = hr[num_trials_to_remove:]\n",
    "hr = scaler.fit_transform(hr)\n",
    "\n",
    "# pupil data\n",
    "pupil = pd.read_csv('data/features_4_2/pupil/' + str(sub) + '.csv')\n",
    "pupil = pupil[num_trials_to_remove:]\n",
    "pupil = scaler.fit_transform(pupil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "string_sub = extract_correct_csv.read_correct_subject_csv(sub)\n",
    "\n",
    "df_ = pd.read_csv('data/LookAtMe_0' + str(string_sub) + '.csv', sep='\\t')\n",
    "df_ = df_[num_trials_to_remove:]\n",
    "label = np.array(list([int(d > 2) for d in df_['rating']]))\n",
    "E = label[:, np.newaxis]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "img = ?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# num trials\n",
    "TEST_PERC = 0.2\n",
    "\n",
    "eda = pd.DataFrame(eda)\n",
    "eda = eda.reset_index().drop(columns=('index'))\n",
    "pupil = pd.DataFrame(pupil)\n",
    "pupil = pupil.reset_index().drop(columns=('index'))\n",
    "hr = pd.DataFrame(hr)\n",
    "hr = hr.reset_index().drop(columns=('index'))\n",
    "img= pd.DataFrame(img)\n",
    "img = img.reset_index().drop(columns=('index'))\n",
    "E = pd.DataFrame(E)\n",
    "E = E.reset_index().drop(columns=('index'))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=3, test_size=TEST_PERC, random_state=123)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "for i, (train_index, test_index) in enumerate(sss.split(eda, E)):\n",
    "    N_train = len(train_index)\n",
    "    eda_train = eda.iloc[train_index, :]\n",
    "    eda_test = eda.iloc[test_index, :]\n",
    "    hr_train = hr.iloc[train_index, :]\n",
    "    hr_test = hr.iloc[test_index, :]\n",
    "    pupil_train = pupil.iloc[train_index, :]\n",
    "    pupil_test = pupil.iloc[test_index, :]\n",
    "    img_train = img.iloc[train_index, :]\n",
    "    img_test = img.iloc[test_index, :]\n",
    "    e_labels_train = E.iloc[train_index, :]\n",
    "    e_labels_test = E.iloc[test_index, :]\n",
    "\n",
    "    # dimensions of each signal\n",
    "    d_eda = eda_train.shape[1]\n",
    "    d_hr = hr_train.shape[1]\n",
    "    d_pupil = pupil_train.shape[1]\n",
    "    d_e = e_labels_train.shape[1]\n",
    "    d_img = img_train.shape[1]\n",
    "\n",
    "    # model definition\n",
    "    with pm.Model() as PPCA_identified:\n",
    "        # model coordinates\n",
    "        PPCA_identified.add_coord(\"latent_columns\", np.arange(k), mutable=True)\n",
    "        PPCA_identified.add_coord(\"rows\", np.arange(N_train), mutable=True)\n",
    "        PPCA_identified.add_coord(\"observed_eda\", np.arange(d_eda), mutable=False)\n",
    "        PPCA_identified.add_coord(\"observed_hr\", np.arange(d_hr), mutable=False)\n",
    "        PPCA_identified.add_coord(\"observed_pupil\", np.arange(d_pupil), mutable=False)\n",
    "        PPCA_identified.add_coord(\"observed_img\",np.arange(d_img),mutable=False)\n",
    "        PPCA_identified.add_coord(\"observed_label\", np.arange(d_e), mutable=False)\n",
    "\n",
    "        hr_data = pm.MutableData(\"hr_data\", hr_train.T, dims=[\"observed_hr\", \"rows\"])\n",
    "        eda_data = pm.MutableData(\"eda_data\", eda_train.T, dims=(\"observed_eda\", \"rows\"))\n",
    "        pupil_data = pm.MutableData(\"pupil_data\", pupil_train.T, dims=(\"observed_pupil\", \"rows\"))\n",
    "        img_data = pm.MutableData(\"img_data\", img_train.T, dims=(\"observed_img\",\"rows\"))\n",
    "\n",
    "        W_eda = makeW(d_eda, k, (\"observed_eda\", \"latent_columns\"), 'W_eda')\n",
    "        W_hr = makeW(d_hr, k, (\"observed_hr\", \"latent_columns\"), 'W_hr')\n",
    "        W_pupil = makeW(d_pupil, k, (\"observed_pupil\", \"latent_columns\"), 'W_pupil')\n",
    "        W_img = makeW(d_img, k, (\"observed_img\",\"latent_columns\"),\"W_img\")\n",
    "        W_e = pm.Normal(\"W_e\", dims=[\"observed_label\", \"latent_columns\"])\n",
    "\n",
    "        C = pm.Normal(\"C\", dims=[\"latent_columns\", \"rows\"])\n",
    "\n",
    "        psi_eda = pm.HalfNormal(\"psi_eda\", 1.0)\n",
    "        X_eda = pm.Normal(\"X_eda\", mu=at.dot(W_eda, C), sigma=psi_eda, observed=eda_data,\n",
    "                          dims=[\"observed_eda\", \"rows\"])\n",
    "\n",
    "        psi_hr = pm.HalfNormal(\"psi_hr\", 1.0)\n",
    "        X_hr = pm.Normal(\"X_hr\", mu=at.dot(W_hr, C), sigma=psi_hr, observed=hr_data, dims=[\"observed_hr\", \"rows\"])\n",
    "\n",
    "        psi_pupil = pm.HalfNormal(\"psi_pupil\", 1.0)\n",
    "        X_pupil = pm.Normal(\"X_pupil\", mu=at.dot(W_pupil, C), sigma=psi_pupil, observed=pupil_data,\n",
    "                            dims=[\"observed_pupil\", \"rows\"])\n",
    "\n",
    "        X_img = pm.Categorical('X_img', p=pm.math.softmax(at.dot(W_img,C)), dims=[\"observed_images\",\"rows\"], observed=img_data)\n",
    "\n",
    "        X_e = pm.Bernoulli(\"X_e\", p=pm.math.sigmoid(at.dot(W_e, C)), dims=[\"observed_label\", \"rows\"],observed=e_labels_train.T)\n",
    "\n",
    "\n",
    "    with PPCA_identified:\n",
    "        approx = pm.fit(100000, callbacks=[pm.callbacks.CheckParametersConvergence(tolerance=1e-4)])\n",
    "        trace = approx.sample(1000)\n",
    "    with PPCA_identified:\n",
    "        posterior_predictive = pm.sample_posterior_predictive(\n",
    "            trace, var_names=[\"X_e\"], random_seed=123)\n",
    "\n",
    "    e_pred_train = posterior_predictive.posterior_predictive['X_e']\n",
    "    e_pred_mode_train = np.squeeze(stats.mode(e_pred_train[0], keepdims=False)[0])[:, np.newaxis]\n",
    "    train_accuracy_exp = accuracy_score(e_labels_train, e_pred_mode_train)\n",
    "\n",
    "    # test\n",
    "    e_pred_mode_test = my_post_predict(trace, hr_test, eda_test, pupil_test, img_test)\n",
    "    test_accuracy_exp = accuracy_score(e_labels_test, e_pred_mode_test)\n",
    "\n",
    "\n",
    "    row = [sub, k, i, train_accuracy_exp, test_accuracy_exp]\n",
    "    with open(FILENAME, 'a') as f:\n",
    "        write = csv.writer(f)\n",
    "        write.writerow(row)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
