{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!who"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-13 16:19:35.910023: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-13 16:19:36.064704: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-13 16:19:36.064730: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-13 16:19:36.769357: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-13 16:19:36.769449: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-13 16:19:36.769459: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import aesara.tensor as at\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import extract_correct_csv\n",
    "\n",
    "from deepemogp import feature_extractor\n",
    "from deepemogp.signal import physio as physio\n",
    "from deepemogp import datasets as datasets\n",
    "from deepemogp.signal import behavior as behavior\n",
    "\n",
    "\n",
    "import logging\n",
    "import pymc as pm\n",
    "import numpy as np\n",
    "import arviz as az\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import jax\n",
    "jax.default_backend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "jax.devices()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "valid_subject = extract_correct_csv.extract_only_valid_subject()\n",
    "valid_k_list = list(range(1, 10))\n",
    "\n",
    "k=5\n",
    "i =2\n",
    "num_trials_to_remove = 48\n",
    "\n",
    "string_subject = extract_correct_csv.read_correct_subject_csv(i)\n",
    "csv_ = 'data/LookAtMe_0' + string_subject + '.csv'\n",
    "# csv_ = '/home/paolo/matteo/matteo/unimi/tesi_master/code/osfstorage-archive/behavior/LookAtMe_045.csv'\n",
    "global_data = pd.read_csv(csv_, sep='\\t')\n",
    "y = np.array(list([int(d > 2) for d in global_data['rating']]))\n",
    "e_labels = y[:, np.newaxis]  # rating > 2\n",
    "e_labels = e_labels[num_trials_to_remove:]\n",
    "N_e = e_labels.shape[0]\n",
    "D_e = e_labels.shape[1]\n",
    "\n",
    "TRIAL = 160\n",
    "\n",
    "hr = pd.read_csv('data/features/hr/'+str(i)+'.csv')\n",
    "hr = hr[num_trials_to_remove:]\n",
    "\n",
    "eda = pd.read_csv('data/features/eda/' + str(i) + '.csv')\n",
    "eda = eda[num_trials_to_remove:]\n",
    "\n",
    "pupil = pd.read_csv('data/features/pupil/' + str(i) + '.csv')\n",
    "pupil = pupil[num_trials_to_remove:]\n",
    "\n",
    "N_pupil = pupil.shape[0]\n",
    "D_pupil = pupil.shape[1]\n",
    "\n",
    "N_hr = hr.shape[0]\n",
    "D_hr = hr.shape[1]\n",
    "\n",
    "N_eda = eda.shape[0]\n",
    "D_eda = eda.shape[1]\n",
    "K = k"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112 60\n"
     ]
    }
   ],
   "source": [
    "print(N_eda,D_eda)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2.2\n",
      "2.11.0\n",
      "0.19.0\n"
     ]
    }
   ],
   "source": [
    "print(pm.__version__)\n",
    "print(tf.__version__)\n",
    "print(tfp.__version__)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [10], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;129m@pm\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmodel\u001B[39m():\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;66;03m# dati osservabili\u001B[39;00m\n\u001B[1;32m      4\u001B[0m     hr_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01myield\u001B[39;00m pm\u001B[38;5;241m.\u001B[39mMutableData(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhr_data\u001B[39m\u001B[38;5;124m\"\u001B[39m, hr\u001B[38;5;241m.\u001B[39mT)\n\u001B[1;32m      5\u001B[0m     pupil_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01myield\u001B[39;00m pm\u001B[38;5;241m.\u001B[39mMutableData(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpupil_data\u001B[39m\u001B[38;5;124m\"\u001B[39m, pupil\u001B[38;5;241m.\u001B[39mT)\n",
      "\u001B[0;31mTypeError\u001B[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "@pm.model\n",
    "def model():\n",
    "    # dati osservabili\n",
    "    hr_data = yield pm.MutableData(\"hr_data\", hr.T)\n",
    "    pupil_data = yield pm.MutableData(\"pupil_data\", pupil.T)\n",
    "    eda_data = yield pm.MutableData(\"eda_data\", eda.T)\n",
    "\n",
    "    e_data = yield pm.ConstantData(\"e_data\", e_labels.T)\n",
    "\n",
    "    # matrici pesi\n",
    "    Whr = yield pm.Normal('Whr', mu=at.zeros([D_hr, K]), sigma=2.0 * at.ones([D_hr, K]), shape=[D_hr, K])\n",
    "    Wpupil = yield pm.Normal('Wpupil', mu=at.zeros([D_pupil, K]), sigma=2.0 * at.ones([D_pupil, K]),\n",
    "                       shape=[D_pupil, K])\n",
    "\n",
    "    Weda = yield pm.Normal('Weda', mu=at.zeros([D_eda, K]), sigma=2.0 * at.ones([D_eda, K]), shape=[D_eda, K])\n",
    "\n",
    "    # weight matrix for pain expectation.\n",
    "    # check mu,sigma,shape\n",
    "    We = yield pm.Normal('W_e', mu=at.zeros([D_e, K]), sigma=2.0 * at.ones([D_e, K]), shape=[D_e, K])\n",
    "\n",
    "    # latent space\n",
    "    c = yield pm.Normal('c', mu=at.zeros([N_hr, K]), sigma=at.ones([N_hr, K]), shape=[N_hr, K])\n",
    "\n",
    "    # dati dell'hrv interpretati come una gaussiana\n",
    "    mu_hr = yield pm.Normal('mu_hr', Whr.dot(c.T), at.ones([D_hr, N_hr]))  # hyperprior 1\n",
    "    sigma_hr = yield pm.Exponential('sigma_hr', at.ones([D_hr, N_hr]))  # hyperprior 2\n",
    "    x_hr = yield pm.Normal('x_hr', mu=mu_hr, sigma=sigma_hr, shape=[D_hr, N_hr], observed=hr_data)\n",
    "\n",
    "    # dati della dilatazione pupille interpretati come una gaussiana\n",
    "    mu_pupil = yield pm.Normal('mu_pupil', Wpupil.dot(c.T), at.ones([D_pupil, N_pupil]))  # hyperprior 1\n",
    "    sigma_pupil = yield pm.Exponential('sigma_pupil', at.ones([D_pupil, N_pupil]))  # hyperprior 2\n",
    "    x_pupil = yield pm.Normal('x_pupil', mu=mu_pupil, sigma=sigma_pupil, shape=[D_pupil, N_pupil],\n",
    "                        observed=pupil_data)\n",
    "\n",
    "    # eda\n",
    "    mu_eda = yield pm.Normal('mu_eda', Weda.dot(c.T), at.ones([D_eda, N_eda]))  # hyperprior 1\n",
    "    sigma_eda = yield pm.Exponential('sigma_eda', at.ones([D_eda, N_eda]))  # hyperprior 2\n",
    "    x_eda = yield pm.Normal('x_eda', mu=mu_eda, sigma=sigma_eda, shape=[D_eda, N_eda], observed=eda_data)\n",
    "\n",
    "    # pain expectation. ci√≤ che dovremmo inferire dato c\n",
    "    # due strade: binary o multiclass (1-4)\n",
    "    # p = probability of success?\n",
    "    x_e = yield pm.Bernoulli('x_e', p=pm.math.sigmoid(We.dot(c.T)), shape=[D_e, N_e], observed=e_data)\n",
    "    return x_e"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "with sPPCA:\n",
    "    approx = pm.fit(100000, callbacks=[pm.callbacks.CheckParametersConvergence(tolerance=1e-4)])\n",
    "    trace = approx.sample(500)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# az.plot_trace(trace);\n",
    "with sPPCA:\n",
    "    # update values of predictors:\n",
    "    # pm.set_data({\"pupil_data\": pupil, \"hr_data\": hr, \"eda_data\": eda})\n",
    "    # use the updated values and predict outcomes and probabilities:\n",
    "    posterior_predictive = pm.sample_posterior_predictive(\n",
    "        trace, random_seed=123)\n",
    "eda_pred = posterior_predictive.posterior_predictive[\"x_eda\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eda_pred = np.squeeze(eda_pred.mean('draw', keepdims='false')[0]).to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "edapred_ = eda_pred.T\n",
    "\n",
    "eda_ = eda.to_numpy()\n",
    "\n",
    "corrlist = []\n",
    "for i in range(112):\n",
    "    res = np.corrcoef(eda_[i], edapred_[i])[0][1]\n",
    "    corrlist.append(res)\n",
    "    print('trial '+str(i)+ ' corr: '+str(res.round(3)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def ccc(x, y):\n",
    "    ''' Concordance Correlation Coefficient'''\n",
    "    sxy = np.sum((x - x.mean()) * (y - y.mean())) / x.shape[0]\n",
    "    rhoc = 2 * sxy / (np.var(x) + np.var(y) + (x.mean() - y.mean()) ** 2)\n",
    "    return rhoc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ccc(edapred_[0],eda_[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "eda_[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "edapred_[0].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x=eda_[0]\n",
    "y=eda_pred[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x- x.mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y-y.mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(x - x.mean()) * (y - y.mean())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sxy= np.sum() / x.shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conc = ccc(eda_[0], eda_pred[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pearson_list = []\n",
    "concord_list = []\n",
    "for i in range(112):\n",
    "    pear = np.corrcoef(eda_[i], edapred_[i])[0][1]\n",
    "    conc = ccc(eda_[i], eda_pred[i])\n",
    "    pearson_list.append(pear)\n",
    "    concord_list.append(conc)\n",
    "    # print('trial ' + str(i) + ' corr: ' + str(res.round(3)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_pear = round(np.mean(pearson_list), 4)\n",
    "mean_corc = round(np.mean(concord_list), 4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_subj = round(np.mean(corrlist),4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "        logging.basicConfig(level=logging.INFO, filename=\"logfile\", filemode=\"a+\",\n",
    "                            format=\"%(asctime)-15s %(levelname)-8s %(message)s\")\n",
    "        logging.info(\"Mean corr coeff eda-hr using subj: \" + str(subj_) + \" \" + str(round(mean_subj, 2)) + \" script: \" +\n",
    "             os.path.basename(__file__) + \"latent space dims: \" + str(K))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
