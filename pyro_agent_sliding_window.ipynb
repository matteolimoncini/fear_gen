{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## import"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'1.8.4'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import pyro\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO, MCMC, NUTS\n",
    "import pyro.distributions as dist\n",
    "import pyro.distributions.constraints as constraints\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\",category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from autorank import autorank, plot_stats, create_report, latex_table\n",
    "from pyirr import intraclass_correlation\n",
    "\n",
    "pyro.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import extract_correct_csv\n",
    "valid_sub = extract_correct_csv.extract_only_valid_subject()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def anxious_subjects(path, n, type='top'):\n",
    "    '''\n",
    "\n",
    "    :param path: path sias score or linear deviation score\n",
    "    :param n: number of subjects\n",
    "    :param type: 'top' or 'bot'\n",
    "    :return: top or bot n subjects sorted by sias score\n",
    "    '''\n",
    "    valid_subjects = extract_correct_csv.extract_only_valid_subject()\n",
    "    df = pd.read_csv(path).dropna().reset_index(drop=True)\n",
    "    df = df[df.subject.isin(valid_subjects)]\n",
    "    df['subject'] = [int(x) for x in df['subject']]\n",
    "    if type=='top':\n",
    "        return df.sort_values(by=df.columns[1], ascending=False).subject[:n].values\n",
    "    else:\n",
    "        return df.sort_values(by=df.columns[1], ascending=False).subject[-n:].values\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_315810/148701896.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rational['shock'] = df_rational['shock'].astype(int) # setting shock as int instead of boolean\n",
      "/tmp/ipykernel_315810/148701896.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rational['morphing level'] = [int(d==6) for d in df_rational['morphing level']] # if morphing level==6 -> 1\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "df = pd.read_csv('data/newLookAtMe/newLookAtMe02.csv')\n",
    "df_rational = df[['morphing level', 'shock']] #consider only morphing level and shock\n",
    "df_rational['shock'] = df_rational['shock'].astype(int) # setting shock as int instead of boolean\n",
    "df_rational['morphing level'] = [int(d==6) for d in df_rational['morphing level']] # if morphing level==6 -> 1\n",
    "df_rational = df_rational.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def counter_window(data, k=0):\n",
    "    N = data.shape[0]\n",
    "    counter = torch.zeros((N,4))\n",
    "    for i in range(len(data)):\n",
    "        dict_ = {'[0 0]':0, '[0 1]': 0, '[1 0]':0, '[1 1]':0}\n",
    "        if k == 0 or k > i:\n",
    "            tmp_data = data[:i+1]\n",
    "        else:\n",
    "            tmp_data = data[i-k:i+1]\n",
    "            #print('im here')\n",
    "        # count occurencies\n",
    "        for x in tmp_data:\n",
    "            dict_[str(x)] += 1\n",
    "        values = np.array(list(dict_.values()))\n",
    "        counter[i] = torch.tensor(values)\n",
    "    return counter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "counter = counter_window(df_rational, 3)\n",
    "counter = counter.reshape((len(df_rational), 2, 2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# categorical/multinomial distribution\n",
    "\n",
    "# uniform prior\n",
    "prior_counts = torch.ones((2,2))\n",
    "\n",
    "\n",
    "#model\n",
    "def model(data):\n",
    "    prior = pyro.sample(\"prior\", dist.Dirichlet(prior_counts))\n",
    "    total_counts = int(data.sum())\n",
    "    pyro.sample(\"likelihood\", dist.Multinomial(total_counts, prior), obs=data)\n",
    "\n",
    "\n",
    "nuts_kernel = NUTS(model)\n",
    "num_samples, warmup_steps = (300, 200)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=num_samples, warmup_steps=warmup_steps, disable_progbar=True)\n",
    "all_means = []\n",
    "\n",
    "# sampling\n",
    "for i in range(len(counter)):\n",
    "    mcmc.run(counter[i])\n",
    "    hmc_samples = {k: v.detach().cpu().numpy()\n",
    "                   for k, v in mcmc.get_samples().items()}\n",
    "    means = hmc_samples['prior'].mean(axis=0)\n",
    "    stds = hmc_samples['prior'].std(axis=0)\n",
    "    print('observation: ', df_rational[i])\n",
    "    print('probabilities: ', means)\n",
    "    all_means.append(means)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analysis sliding window K"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "k_wind = [2, 5, 10, 25, 50, 100, 150]\n",
    "HAB_TRIALS = 16\n",
    "\n",
    "path_sias = 'data/sias_score.csv'\n",
    "path_lds = 'data/lds_subjects.csv'\n",
    "\n",
    "len_sub = 6\n",
    "top_lds = anxious_subjects(path_lds, len_sub, 'top')\n",
    "bot_lds = anxious_subjects(path_lds, len_sub, 'bot')\n",
    "\n",
    "top_sias = anxious_subjects(path_sias, len_sub)\n",
    "bot_sias = anxious_subjects(path_sias, len_sub, 'bot')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "df_correlation = pd.DataFrame(columns=['subject','k','pearson','r2score','person_disc','cohen_disc'])\n",
    "\n",
    "for k in list(k_wind):\n",
    "\n",
    "    # read output of the rational model with different K\n",
    "    array_csplus_simulated = np.load('output/pyro/sliding_wind/k'+str(k)+'_csplus.npy',allow_pickle=True)\n",
    "    array_csminus_simulated = np.load('output/pyro/sliding_wind/k'+str(k)+'_csminus.npy',allow_pickle=True)\n",
    "    total_array_simulated = np.load('output/pyro/sliding_wind/k'+str(k)+'_total.npy',allow_pickle=True)\n",
    "\n",
    "    rating_rational_subj = total_array_simulated[HAB_TRIALS:] #remove habituation trials\n",
    "\n",
    "\n",
    "    for sub in valid_sub:\n",
    "        subj_ = extract_correct_csv.read_correct_subject_csv(sub)\n",
    "\n",
    "        #read data of real subjects\n",
    "        df_sub = pd.read_csv('data/newLookAtMe/newLookAtMe'+subj_+'.csv')\n",
    "        df_sub = df_sub[['shock', 'rating', 'morphing level']]\n",
    "        df_sub['shock'] = df_sub['shock'].astype(int) #convert shock from boolean to int\n",
    "        df_sub['morphing level'] = [int(d == 6) for d in df_sub['morphing level']]\n",
    "        df_sub['rating'] = df_sub['rating'].replace([1, 2, 3, 4, 5], [0.2, 0.4, 0.6, 0.8, 1]) #convert vote into (0,1)\n",
    "        df_sub_learn = df_sub[HAB_TRIALS:] #remove habituation trials\n",
    "        rating_sub = np.array(df_sub_learn['rating'])\n",
    "\n",
    "        rating_rational = rating_rational_subj\n",
    "        #remove trial from rating agent simulation and real data if in one list is nan\n",
    "        bad = ~np.logical_or(np.isnan(rating_sub), np.isnan(rating_rational))\n",
    "        rating_sub = np.compress(bad, rating_sub)\n",
    "        rating_rational = np.compress(bad, rating_rational)\n",
    "\n",
    "        #discretization of rating rational\n",
    "        round_vector = np.array([0.2, 0.4, 0.6, 0.8, 1])\n",
    "        rating_rational_discr = np.round(rating_rational / 0.2) * 0.2\n",
    "        rating_rational_discr = np.clip(rating_rational_discr, round_vector.min(), round_vector.max())\n",
    "\n",
    "        # calculate pearson correlation coefficient between k-rational model and real data\n",
    "        pearson = round(np.corrcoef(rating_sub,rating_rational)[0][1],2)\n",
    "\n",
    "        # calculate r2 score between k-rational model and real data\n",
    "        r2 = round(r2_score(rating_sub,rating_rational),2)\n",
    "\n",
    "        # calculate pearson correlation coefficient between k-rational model and real data using discrete values for k-rational model\n",
    "        pearson_disc = round(np.corrcoef(rating_sub,rating_rational_discr)[0][1],2)\n",
    "\n",
    "        # calculate cohen kappa between k-rational model and real data using discrete values for k-rational model\n",
    "        cohen_disc = round(cohen_kappa_score(rating_sub*10,rating_rational_discr*10),2)\n",
    "\n",
    "        # write line\n",
    "        df_tmp = pd.DataFrame({'subject':sub,'k':k,'pearson':pearson,'r2score':r2,'person_disc':pearson_disc,'cohen_disc':cohen_disc},index=np.arange(1))\n",
    "        df_correlation = pd.concat([df_correlation,df_tmp])\n",
    "\n",
    "df_correlation['subject'] = [float(x) for x in df_correlation['subject']] #convert subjects into float\n",
    "\n",
    "# read social anxiety values\n",
    "sias_df = pd.read_csv('data/sias_score.csv').drop(columns='social_anxiety')\n",
    "sias_df['subject'] = [float(x) for x in sias_df['subject']] #convert subjects into float\n",
    "\n",
    "# read linear deviation score (how much this subject do fear generalization)\n",
    "lds_df = pd.read_csv('data/lds_subjects.csv')\n",
    "lds_df['subject'] = [float(x) for x in lds_df['subject']] #convert subjects into float"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# one dataframe with social anxiety, linear devation score and correlation measures for each subject\n",
    "res = pd.merge(sias_df, lds_df)\n",
    "df_correlation = pd.merge(res,df_correlation).dropna().reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "     subject  sias_score    lds    k  pearson  r2score  person_disc  \\\n0        1.0        21.0  0.201    2     0.24    -1.54         0.27   \n1        1.0        21.0  0.201    5     0.30    -2.35         0.30   \n2        1.0        21.0  0.201   10     0.29    -3.22         0.28   \n3        1.0        21.0  0.201   25     0.26    -4.27         0.23   \n4        1.0        21.0  0.201   50     0.23    -4.78         0.22   \n..       ...         ...    ...  ...      ...      ...          ...   \n205     54.0        17.0  1.594   10     0.87     0.03         0.83   \n206     54.0        17.0  1.594   25     0.89    -0.14         0.87   \n207     54.0        17.0  1.594   50     0.90    -0.27         0.85   \n208     54.0        17.0  1.594  100     0.91    -0.31         0.85   \n209     54.0        17.0  1.594  150     0.91    -0.35         0.84   \n\n     cohen_disc  \n0          0.00  \n1          0.06  \n2          0.03  \n3          0.00  \n4         -0.01  \n..          ...  \n205        0.16  \n206        0.14  \n207        0.14  \n208        0.14  \n209        0.13  \n\n[210 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject</th>\n      <th>sias_score</th>\n      <th>lds</th>\n      <th>k</th>\n      <th>pearson</th>\n      <th>r2score</th>\n      <th>person_disc</th>\n      <th>cohen_disc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>21.0</td>\n      <td>0.201</td>\n      <td>2</td>\n      <td>0.24</td>\n      <td>-1.54</td>\n      <td>0.27</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>21.0</td>\n      <td>0.201</td>\n      <td>5</td>\n      <td>0.30</td>\n      <td>-2.35</td>\n      <td>0.30</td>\n      <td>0.06</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>21.0</td>\n      <td>0.201</td>\n      <td>10</td>\n      <td>0.29</td>\n      <td>-3.22</td>\n      <td>0.28</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>21.0</td>\n      <td>0.201</td>\n      <td>25</td>\n      <td>0.26</td>\n      <td>-4.27</td>\n      <td>0.23</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>21.0</td>\n      <td>0.201</td>\n      <td>50</td>\n      <td>0.23</td>\n      <td>-4.78</td>\n      <td>0.22</td>\n      <td>-0.01</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>205</th>\n      <td>54.0</td>\n      <td>17.0</td>\n      <td>1.594</td>\n      <td>10</td>\n      <td>0.87</td>\n      <td>0.03</td>\n      <td>0.83</td>\n      <td>0.16</td>\n    </tr>\n    <tr>\n      <th>206</th>\n      <td>54.0</td>\n      <td>17.0</td>\n      <td>1.594</td>\n      <td>25</td>\n      <td>0.89</td>\n      <td>-0.14</td>\n      <td>0.87</td>\n      <td>0.14</td>\n    </tr>\n    <tr>\n      <th>207</th>\n      <td>54.0</td>\n      <td>17.0</td>\n      <td>1.594</td>\n      <td>50</td>\n      <td>0.90</td>\n      <td>-0.27</td>\n      <td>0.85</td>\n      <td>0.14</td>\n    </tr>\n    <tr>\n      <th>208</th>\n      <td>54.0</td>\n      <td>17.0</td>\n      <td>1.594</td>\n      <td>100</td>\n      <td>0.91</td>\n      <td>-0.31</td>\n      <td>0.85</td>\n      <td>0.14</td>\n    </tr>\n    <tr>\n      <th>209</th>\n      <td>54.0</td>\n      <td>17.0</td>\n      <td>1.594</td>\n      <td>150</td>\n      <td>0.91</td>\n      <td>-0.35</td>\n      <td>0.84</td>\n      <td>0.13</td>\n    </tr>\n  </tbody>\n</table>\n<p>210 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_correlation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check from this if there's something useful"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Rational agent discretisation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "valid_subjects = extract_correct_csv.extract_only_valid_subject()\n",
    "len(valid_subjects)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_array_simulated = np.load('output/pyro/complete_rational/total.npy',allow_pickle=True)\n",
    "total_array_simulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "values = np.array([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "discretized_data = np.digitize(total_array_simulated, values)\n",
    "print(discretized_data.shape)\n",
    "\n",
    "\n",
    "df_global = pd.DataFrame(columns=['Subject', 'Rating rational', 'Rating real'])\n",
    "\n",
    "for sub in valid_subjects:\n",
    "    string_sub = extract_correct_csv.read_correct_subject_csv(sub)\n",
    "    df_sub = pd.read_csv('data/newLookAtMe/newLookAtMe'+string_sub+'.csv')\n",
    "    df_sub = df_sub[16:]\n",
    "    tmp_df = pd.DataFrame({'Subject': sub, 'Rating rational': discretized_data, 'Rating real': df_sub['rating']})\n",
    "    df_global = pd.concat([df_global, tmp_df])\n",
    "\n",
    "df_global = df_global.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "valid_subjects = df_global.Subject.unique()\n",
    "valid_subjects"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dict_results = {}\n",
    "for x in valid_subjects:\n",
    "    df_sub_ = df_global[df_global.Subject == x].dropna().drop(columns=['Subject']).reset_index(drop=True)\n",
    "    df_sub_['Rating rational'] = df_sub_['Rating rational'].astype(float)\n",
    "    result = intraclass_correlation(df_sub_).value\n",
    "    dict_results[x] = result\n",
    "\n",
    "dict_results\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_icc = pd.DataFrame(list(dict_results.items()), columns=['Subject', 'ICC'])\n",
    "df_icc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_sias = 'data/sias_score.csv'\n",
    "path_lds = 'data/lds_subjects.csv'\n",
    "\n",
    "len_sub = 6\n",
    "top_lds = anxious_subjects(path_lds, len_sub, 'top')\n",
    "bot_lds = anxious_subjects(path_lds, len_sub, 'bot')\n",
    "\n",
    "top_sias = anxious_subjects(path_sias, len_sub)\n",
    "bot_sias = anxious_subjects(path_sias, len_sub, 'bot')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_top_sias = df_icc[df_icc.Subject.isin(top_sias)]['ICC'].mean()\n",
    "mean_bot_sias = df_icc[df_icc.Subject.isin(bot_sias)]['ICC'].mean()\n",
    "mean_top_lds = df_icc[df_icc.Subject.isin(top_lds)]['ICC'].mean()\n",
    "mean_bot_lds = df_icc[df_icc.Subject.isin(bot_lds)]['ICC'].mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Average of the first {len_sub} subjects with higher sias score: {round(mean_top_sias, 2)}')\n",
    "print(f'Average of the first {len_sub} subjects with lower sias score: {round(mean_bot_sias, 2)}')\n",
    "print(f'Average of the first {len_sub} subjects with higher linear deviation score: {round(mean_top_lds,2)}')\n",
    "print(f'Average of the first {len_sub} subjects with lower linear deviation score: {round(mean_bot_lds, 2)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
