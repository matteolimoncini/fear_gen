{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## import"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'1.8.4'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import pyro\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO, MCMC, NUTS\n",
    "import pyro.distributions as dist\n",
    "import pyro.distributions.constraints as constraints\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\",category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from autorank import autorank, plot_stats, create_report, latex_table\n",
    "from pyirr import intraclass_correlation\n",
    "\n",
    "pyro.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import extract_correct_csv\n",
    "valid_sub = extract_correct_csv.extract_only_valid_subject()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def anxious_subjects(path, n, type='top'):\n",
    "    '''\n",
    "\n",
    "    :param path: path sias score or linear deviation score\n",
    "    :param n: number of subjects\n",
    "    :param type: 'top' or 'bot'\n",
    "    :return: top or bot n subjects sorted by sias score\n",
    "    '''\n",
    "    valid_subjects = extract_correct_csv.extract_only_valid_subject()\n",
    "    df = pd.read_csv(path).dropna().reset_index(drop=True)\n",
    "    df = df[df.subject.isin(valid_subjects)]\n",
    "    df['subject'] = [int(x) for x in df['subject']]\n",
    "    if type=='top':\n",
    "        return df.sort_values(by=df.columns[1], ascending=False).subject[:n].values\n",
    "    else:\n",
    "        return df.sort_values(by=df.columns[1], ascending=False).subject[-n:].values\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_313340/148701896.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rational['shock'] = df_rational['shock'].astype(int) # setting shock as int instead of boolean\n",
      "/tmp/ipykernel_313340/148701896.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_rational['morphing level'] = [int(d==6) for d in df_rational['morphing level']] # if morphing level==6 -> 1\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "df = pd.read_csv('data/newLookAtMe/newLookAtMe02.csv')\n",
    "df_rational = df[['morphing level', 'shock']] #consider only morphing level and shock\n",
    "df_rational['shock'] = df_rational['shock'].astype(int) # setting shock as int instead of boolean\n",
    "df_rational['morphing level'] = [int(d==6) for d in df_rational['morphing level']] # if morphing level==6 -> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rational = df_rational.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analysis sliding window K"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "k_wind = [2, 5, 10, 25, 50, 100, 150]\n",
    "HAB_TRIALS = 16\n",
    "\n",
    "path_sias = 'data/sias_score.csv'\n",
    "path_lds = 'data/lds_subjects.csv'\n",
    "\n",
    "len_sub = 6\n",
    "top_lds = anxious_subjects(path_lds, len_sub, 'top')\n",
    "bot_lds = anxious_subjects(path_lds, len_sub, 'bot')\n",
    "\n",
    "top_sias = anxious_subjects(path_sias, len_sub)\n",
    "bot_sias = anxious_subjects(path_sias, len_sub, 'bot')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "df_correlation = pd.DataFrame(columns=['subject','k','pearson','r2score','person_disc','cohen_disc'])\n",
    "\n",
    "for k in list(k_wind):\n",
    "\n",
    "    # read output of the rational model with different K\n",
    "    array_csplus_simulated = np.load('output/pyro/sliding_wind/k'+str(k)+'_csplus.npy',allow_pickle=True)\n",
    "    array_csminus_simulated = np.load('output/pyro/sliding_wind/k'+str(k)+'_csminus.npy',allow_pickle=True)\n",
    "    total_array_simulated = np.load('output/pyro/sliding_wind/k'+str(k)+'_total.npy',allow_pickle=True)\n",
    "\n",
    "    rating_rational_subj = total_array_simulated[HAB_TRIALS:] #remove habituation trials\n",
    "\n",
    "\n",
    "    for sub in valid_sub:\n",
    "        subj_ = extract_correct_csv.read_correct_subject_csv(sub)\n",
    "\n",
    "        #read data of real subjects\n",
    "        df_sub = pd.read_csv('data/newLookAtMe/newLookAtMe'+subj_+'.csv')\n",
    "        df_sub = df_sub[['shock', 'rating', 'morphing level']]\n",
    "        df_sub['shock'] = df_sub['shock'].astype(int) #convert shock from boolean to int\n",
    "        df_sub['morphing level'] = [int(d == 6) for d in df_sub['morphing level']]\n",
    "        df_sub['rating'] = df_sub['rating'].replace([1, 2, 3, 4, 5], [0.2, 0.4, 0.6, 0.8, 1]) #convert vote into (0,1)\n",
    "        df_sub_learn = df_sub[HAB_TRIALS:] #remove habituation trials\n",
    "        rating_sub = np.array(df_sub_learn['rating'])\n",
    "\n",
    "        rating_rational = rating_rational_subj\n",
    "        #remove trial from rating agent simulation and real data if in one list is nan\n",
    "        bad = ~np.logical_or(np.isnan(rating_sub), np.isnan(rating_rational))\n",
    "        rating_sub = np.compress(bad, rating_sub)\n",
    "        rating_rational = np.compress(bad, rating_rational)\n",
    "\n",
    "        #discretization of rating rational\n",
    "        round_vector = np.array([0.2, 0.4, 0.6, 0.8, 1])\n",
    "        rating_rational_discr = np.round(rating_rational / 0.2) * 0.2\n",
    "        rating_rational_discr = np.clip(rating_rational_discr, round_vector.min(), round_vector.max())\n",
    "\n",
    "        # calculate pearson correlation coefficient between k-rational model and real data\n",
    "        pearson = round(np.corrcoef(rating_sub,rating_rational)[0][1],2)\n",
    "\n",
    "        # calculate r2 score between k-rational model and real data\n",
    "        r2 = round(r2_score(rating_sub,rating_rational),2)\n",
    "\n",
    "        # calculate pearson correlation coefficient between k-rational model and real data using discrete values for k-rational model\n",
    "        pearson_disc = round(np.corrcoef(rating_sub,rating_rational_discr)[0][1],2)\n",
    "\n",
    "        # calculate cohen kappa between k-rational model and real data using discrete values for k-rational model\n",
    "        cohen_disc = round(cohen_kappa_score(rating_sub*10,rating_rational_discr*10),2)\n",
    "\n",
    "        # write line\n",
    "        df_tmp = pd.DataFrame({'subject':sub,'k':k,'pearson':pearson,'r2score':r2,'person_disc':pearson_disc,'cohen_disc':cohen_disc},index=np.arange(1))\n",
    "        df_correlation = pd.concat([df_correlation,df_tmp])\n",
    "df_correlation['subject'] = [float(x) for x in df_correlation['subject']] #convert subjects into float\n",
    "\n",
    "# read social anxiety values\n",
    "sias_df = pd.read_csv('data/sias_score.csv').drop(columns='social_anxiety')\n",
    "sias_df['subject'] = [float(x) for x in sias_df['subject']] #convert subjects into float\n",
    "\n",
    "# read linear deviation score (how much this subject do fear generalization)\n",
    "lds_df = pd.read_csv('data/lds_subjects.csv')\n",
    "lds_df['subject'] = [float(x) for x in lds_df['subject']] #convert subjects into float"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "             pearson  r2score  person_disc  cohen_disc\nsubject k                                             \n1.0     2       0.24    -1.54         0.27        0.00\n2.0     2       0.57     0.01         0.58        0.15\n4.0     2       0.35    -0.59         0.37        0.07\n5.0     2       0.56     0.04         0.61        0.18\n6.0     2       0.59     0.27         0.62        0.26\n...              ...      ...          ...         ...\n48.0    150     0.53    -1.37         0.44        0.13\n50.0    150     0.25    -2.70         0.23        0.04\n51.0    150     0.70    -0.45         0.61        0.31\n52.0    150     0.67    -0.60         0.65        0.32\n54.0    150     0.91    -0.35         0.84        0.13\n\n[210 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>pearson</th>\n      <th>r2score</th>\n      <th>person_disc</th>\n      <th>cohen_disc</th>\n    </tr>\n    <tr>\n      <th>subject</th>\n      <th>k</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1.0</th>\n      <th>2</th>\n      <td>0.24</td>\n      <td>-1.54</td>\n      <td>0.27</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>2.0</th>\n      <th>2</th>\n      <td>0.57</td>\n      <td>0.01</td>\n      <td>0.58</td>\n      <td>0.15</td>\n    </tr>\n    <tr>\n      <th>4.0</th>\n      <th>2</th>\n      <td>0.35</td>\n      <td>-0.59</td>\n      <td>0.37</td>\n      <td>0.07</td>\n    </tr>\n    <tr>\n      <th>5.0</th>\n      <th>2</th>\n      <td>0.56</td>\n      <td>0.04</td>\n      <td>0.61</td>\n      <td>0.18</td>\n    </tr>\n    <tr>\n      <th>6.0</th>\n      <th>2</th>\n      <td>0.59</td>\n      <td>0.27</td>\n      <td>0.62</td>\n      <td>0.26</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>48.0</th>\n      <th>150</th>\n      <td>0.53</td>\n      <td>-1.37</td>\n      <td>0.44</td>\n      <td>0.13</td>\n    </tr>\n    <tr>\n      <th>50.0</th>\n      <th>150</th>\n      <td>0.25</td>\n      <td>-2.70</td>\n      <td>0.23</td>\n      <td>0.04</td>\n    </tr>\n    <tr>\n      <th>51.0</th>\n      <th>150</th>\n      <td>0.70</td>\n      <td>-0.45</td>\n      <td>0.61</td>\n      <td>0.31</td>\n    </tr>\n    <tr>\n      <th>52.0</th>\n      <th>150</th>\n      <td>0.67</td>\n      <td>-0.60</td>\n      <td>0.65</td>\n      <td>0.32</td>\n    </tr>\n    <tr>\n      <th>54.0</th>\n      <th>150</th>\n      <td>0.91</td>\n      <td>-0.35</td>\n      <td>0.84</td>\n      <td>0.13</td>\n    </tr>\n  </tbody>\n</table>\n<p>210 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "\n",
    "# one dataframe with social anxiety, linear devation score and correlation measures for each subject\n",
    "df_correlation = pd.concat([sias_df.set_index('subject'), lds_df.set_index('subject'), df_correlation.set_index(['subject','k'])], axis=1).reset_index()\n",
    "df_correlation_not_nan = df_correlation.dropna()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "Empty DataFrame\nColumns: [index, sias_score, lds, pearson, r2score, person_disc, cohen_disc]\nIndex: []",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>sias_score</th>\n      <th>lds</th>\n      <th>pearson</th>\n      <th>r2score</th>\n      <th>person_disc</th>\n      <th>cohen_disc</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_correlation_not_nan"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_corr_notna['sias_score'] = [round(x,2) for x in preprocessing.normalize([df_corr_notna['sias_score']])[0]]\n",
    "df_corr_notna['lds'] = [round(x,2) for x in preprocessing.normalize([df_corr_notna['lds']])[0]]\n",
    "df_corr_notna['pearson'] = [round(x,2) for x in preprocessing.normalize([df_corr_notna['pearson']])[0]]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_corr_notna['subject'] = [int(x) for x in df_corr_notna['subject']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lds_ = df_corr_notna.sort_values('lds').reset_index().drop(columns='index')\n",
    "lower_lds = lds_[:5]\n",
    "higher_lds = lds_[-5:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = tuple(df_corr_notna['subject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {'pearson':(),'lds':(),'sias':()}\n",
    "for index,row in df_corr_notna.iterrows():\n",
    "    new_p = values['pearson'] + (row['pearson'],)\n",
    "    values.update({'pearson':new_p})\n",
    "    new_l = values['lds'] + (row['lds'],)\n",
    "    values.update({'lds':new_l})\n",
    "    new_s = values['sias'] + (row['sias_score'],)\n",
    "    values.update({'sias':new_s})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_no_sias = {'pearson':(),'lds':()}\n",
    "for index,row in df_corr_notna.iterrows():\n",
    "    new_p = values_no_sias['pearson'] + (row['pearson'],)\n",
    "    values_no_sias.update({'pearson':new_p})\n",
    "    new_l = values_no_sias['lds'] + (row['lds'],)\n",
    "    values_no_sias.update({'lds':new_l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = tuple(df_corr_notna['subject'])\n",
    "values_no_lds = {'pearson': (), 'sias': ()}\n",
    "for index, row in df_corr_notna.iterrows():\n",
    "    new_p = values_no_lds['pearson'] + (row['pearson'],)\n",
    "    values_no_lds.update({'pearson': new_p})\n",
    "    new_s = values_no_lds['sias'] + (row['sias_score'],)\n",
    "    values_no_lds.update({'sias': new_s})"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## plot correlation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(subjects))  # the label locations\n",
    "width = 0.15  # the width of the bars\n",
    "multiplier = 0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,8),constrained_layout=True)\n",
    "\n",
    "for attribute, measurement in values_no_lds.items():\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "    #ax.bar_label(rects, padding=3)\n",
    "    multiplier += 1\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Length (mm)')\n",
    "ax.set_title('correlation attributes by subjects')\n",
    "ax.set_xticks(x + width, subjects)\n",
    "ax.legend(loc='upper left', ncols=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(subjects))  # the label locations\n",
    "width = 0.15  # the width of the bars\n",
    "multiplier = 0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,8),constrained_layout=True)\n",
    "\n",
    "for attribute, measurement in values_no_sias.items():\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "    #ax.bar_label(rects, padding=3)\n",
    "    multiplier += 1\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Length (mm)')\n",
    "ax.set_title('correlation attributes by subjects')\n",
    "ax.set_xticks(x + width, subjects)\n",
    "ax.legend(loc='upper left', ncols=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(subjects))  # the label locations\n",
    "width = 0.15  # the width of the bars\n",
    "multiplier = 0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,8),constrained_layout=True)\n",
    "\n",
    "for attribute, measurement in values.items():\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, measurement, width, label=attribute)\n",
    "    #ax.bar_label(rects, padding=3)\n",
    "    multiplier += 1\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Length (mm)')\n",
    "ax.set_title('correlation attributes by subjects')\n",
    "ax.set_xticks(x + width, subjects)\n",
    "ax.legend(loc='upper left', ncols=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rational agent sliding window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to have a rational agent with a limited memory over previous trials.\n",
    "k = param sliding window dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import extract_correct_csv\n",
    "valid_sub = extract_correct_csv.extract_only_valid_subject()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "df = pd.read_csv('data/newLookAtMe/newLookAtMe02.csv')\n",
    "df_rational = df[['morphing level', 'shock']]\n",
    "df_rational['shock'] = df_rational['shock'].astype(int) #setting shock as int instead of boolean\n",
    "df_rational['morphing level'] = [int(d==6) for d in df_rational['morphing level']] # if morphing level==6 -> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_np = df_rational.to_numpy()\n",
    "\n",
    "\n",
    "def counter_window(data, k=0):\n",
    "    N = data.shape[0]\n",
    "    counter = torch.zeros((N,4))\n",
    "    for i in range(len(data)):\n",
    "        dict_ = {'[0 0]':0, '[0 1]': 0, '[1 0]':0, '[1 1]':0}\n",
    "        if k == 0 or k > i:\n",
    "            tmp_data = data[:i+1]\n",
    "        else:\n",
    "            tmp_data = data[i-k:i+1]\n",
    "            #print('im here')\n",
    "        # count occurencies\n",
    "        for x in tmp_data:\n",
    "            dict_[str(x)] += 1\n",
    "        values = np.array(list(dict_.values()))\n",
    "        counter[i] = torch.tensor(values)\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = counter_window(data_np, 3)\n",
    "\n",
    "counter = counter.reshape((len(data_np), 2, 2))\n",
    "counter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical/multinomial distribution\n",
    "\n",
    "# uniform prior\n",
    "prior_counts = torch.ones((2,2))\n",
    "\n",
    "\n",
    "#model\n",
    "def model(data):\n",
    "    prior = pyro.sample(\"prior\", dist.Dirichlet(prior_counts))\n",
    "    total_counts = int(data.sum())\n",
    "    pyro.sample(\"likelihood\", dist.Multinomial(total_counts, prior), obs=data)\n",
    "\n",
    "\n",
    "nuts_kernel = NUTS(model)\n",
    "num_samples, warmup_steps = (300, 200)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=num_samples, warmup_steps=warmup_steps, disable_progbar=True)\n",
    "all_means = []\n",
    "\n",
    "# sampling\n",
    "for i in range(len(counter)):\n",
    "    mcmc.run(counter[i])\n",
    "    hmc_samples = {k: v.detach().cpu().numpy()\n",
    "                   for k, v in mcmc.get_samples().items()}\n",
    "    means = hmc_samples['prior'].mean(axis=0)\n",
    "    stds = hmc_samples['prior'].std(axis=0)\n",
    "    print('observation: ', data_np[i])\n",
    "    print('probabilities: ', means)\n",
    "    all_means.append(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Rational agent discretisation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "valid_subjects = extract_correct_csv.extract_only_valid_subject()\n",
    "len(valid_subjects)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_array_simulated = np.load('output/pyro/complete_rational/total.npy',allow_pickle=True)\n",
    "total_array_simulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "values = np.array([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "discretized_data = np.digitize(total_array_simulated, values)\n",
    "print(discretized_data.shape)\n",
    "\n",
    "\n",
    "df_global = pd.DataFrame(columns=['Subject', 'Rating rational', 'Rating real'])\n",
    "\n",
    "for sub in valid_subjects:\n",
    "    string_sub = extract_correct_csv.read_correct_subject_csv(sub)\n",
    "    df_sub = pd.read_csv('data/newLookAtMe/newLookAtMe'+string_sub+'.csv')\n",
    "    df_sub = df_sub[16:]\n",
    "    tmp_df = pd.DataFrame({'Subject': sub, 'Rating rational': discretized_data, 'Rating real': df_sub['rating']})\n",
    "    df_global = pd.concat([df_global, tmp_df])\n",
    "\n",
    "df_global = df_global.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# useless up to now\n",
    "'''df_global = df_global.groupby('Subject', as_index=False).agg({'Rating rational': lambda x: x.tolist(), 'Rating real': lambda x: x.tolist()})\n",
    "df_global['Rating rational'] = df_global['Rating rational'].apply(lambda x: np.array(x))\n",
    "df_global['Rating real'] = df_global['Rating real'].apply(lambda x: np.array(x))'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "valid_subjects = df_global.Subject.unique()\n",
    "valid_subjects"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dict_results = {}\n",
    "for x in valid_subjects:\n",
    "    df_sub_ = df_global[df_global.Subject == x].dropna().drop(columns=['Subject']).reset_index(drop=True)\n",
    "    df_sub_['Rating rational'] = df_sub_['Rating rational'].astype(float)\n",
    "    result = intraclass_correlation(df_sub_).value\n",
    "    dict_results[x] = result\n",
    "\n",
    "dict_results\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_icc = pd.DataFrame(list(dict_results.items()), columns=['Subject', 'ICC'])\n",
    "df_icc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_sias = 'data/sias_score.csv'\n",
    "path_lds = 'data/lds_subjects.csv'\n",
    "\n",
    "len_sub = 6\n",
    "top_lds = anxious_subjects(path_lds, len_sub, 'top')\n",
    "bot_lds = anxious_subjects(path_lds, len_sub, 'bot')\n",
    "\n",
    "top_sias = anxious_subjects(path_sias, len_sub)\n",
    "bot_sias = anxious_subjects(path_sias, len_sub, 'bot')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_top_sias = df_icc[df_icc.Subject.isin(top_sias)]['ICC'].mean()\n",
    "mean_bot_sias = df_icc[df_icc.Subject.isin(bot_sias)]['ICC'].mean()\n",
    "mean_top_lds = df_icc[df_icc.Subject.isin(top_lds)]['ICC'].mean()\n",
    "mean_bot_lds = df_icc[df_icc.Subject.isin(bot_lds)]['ICC'].mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Average of the first {len_sub} subjects with higher sias score: {round(mean_top_sias, 2)}')\n",
    "print(f'Average of the first {len_sub} subjects with lower sias score: {round(mean_bot_sias, 2)}')\n",
    "print(f'Average of the first {len_sub} subjects with higher linear deviation score: {round(mean_top_lds,2)}')\n",
    "print(f'Average of the first {len_sub} subjects with lower linear deviation score: {round(mean_bot_lds, 2)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
