{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## import"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'1.8.4'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import pyro\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO, MCMC, NUTS\n",
    "import pyro.distributions as dist\n",
    "import pyro.distributions.constraints as constraints\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\",category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from autorank import autorank, plot_stats, create_report, latex_table\n",
    "from pyirr import intraclass_correlation\n",
    "\n",
    "pyro.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import extract_correct_csv\n",
    "valid_sub = extract_correct_csv.extract_only_valid_subject()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def anxious_subjects(path, n, type='top'):\n",
    "    '''\n",
    "\n",
    "    :param path: path sias score or linear deviation score\n",
    "    :param n: number of subjects\n",
    "    :param type: 'top' or 'bot'\n",
    "    :return: top or bot n subjects sorted by sias score\n",
    "    '''\n",
    "    valid_subjects = extract_correct_csv.extract_only_valid_subject()\n",
    "    df = pd.read_csv(path).dropna().reset_index(drop=True)\n",
    "    df = df[df.subject.isin(valid_subjects)]\n",
    "    df['subject'] = [int(x) for x in df['subject']]\n",
    "    if type=='top':\n",
    "        return df.sort_values(by=df.columns[1], ascending=False).subject[:n].values\n",
    "    else:\n",
    "        return df.sort_values(by=df.columns[1], ascending=False).subject[-n:].values\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def counter_window(data, k=0):\n",
    "    N = data.shape[0]\n",
    "    counter = torch.zeros((N,4))\n",
    "    for i in range(len(data)):\n",
    "        dict_ = {'[0 0]':0, '[0 1]': 0, '[1 0]':0, '[1 1]':0}\n",
    "        if k == 0 or k > i:\n",
    "            tmp_data = data[:i+1]\n",
    "        else:\n",
    "            tmp_data = data[i-k:i+1]\n",
    "            #print('im here')\n",
    "        # count occurencies\n",
    "        for x in tmp_data:\n",
    "            dict_[str(x)] += 1\n",
    "        values = np.array(list(dict_.values()))\n",
    "        counter[i] = torch.tensor(values)\n",
    "    return counter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('data/newLookAtMe/newLookAtMe02.csv')\n",
    "df_rational = df[['morphing level', 'shock']] #consider only morphing level and shock\n",
    "df_rational['shock'] = df_rational['shock'].astype(int) # setting shock as int instead of boolean\n",
    "df_rational['morphing level'] = [int(d==6) for d in df_rational['morphing level']] # if morphing level==6 -> 1\n",
    "df_rational = df_rational.to_numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "counter = counter_window(df_rational, 3)\n",
    "counter = counter.reshape((len(df_rational), 2, 2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# model sliding window"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation:  [0 0]\n",
      "probabilities:  [[0.68742085 0.3125795 ]\n",
      " [0.4654659  0.5345343 ]]\n",
      "observation:  [1 0]\n",
      "probabilities:  [[0.6822231  0.31777716]\n",
      " [0.65356684 0.3464332 ]]\n",
      "observation:  [1 0]\n",
      "probabilities:  [[0.6839205  0.31607947]\n",
      " [0.7440639  0.25593612]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [7], line 22\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# sampling\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(counter)):\n\u001B[0;32m---> 22\u001B[0m     mcmc\u001B[38;5;241m.\u001B[39mrun(counter[i])\n\u001B[1;32m     23\u001B[0m     hmc_samples \u001B[38;5;241m=\u001B[39m {k: v\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[1;32m     24\u001B[0m                    \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m mcmc\u001B[38;5;241m.\u001B[39mget_samples()\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[1;32m     25\u001B[0m     means \u001B[38;5;241m=\u001B[39m hmc_samples[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprior\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mmean(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/pyro/poutine/messenger.py:12\u001B[0m, in \u001B[0;36m_context_wrap\u001B[0;34m(context, fn, *args, **kwargs)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_context_wrap\u001B[39m(context, fn, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m context:\n\u001B[0;32m---> 12\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/pyro/infer/mcmc/api.py:563\u001B[0m, in \u001B[0;36mMCMC.run\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    554\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m optional(\n\u001B[1;32m    555\u001B[0m     pyro\u001B[38;5;241m.\u001B[39mvalidation_enabled(\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdisable_validation),\n\u001B[1;32m    556\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdisable_validation \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    560\u001B[0m     \u001B[38;5;66;03m# This also resolves \"RuntimeError: Cowardly refusing to serialize non-leaf tensor which\u001B[39;00m\n\u001B[1;32m    561\u001B[0m     \u001B[38;5;66;03m# requires_grad\", which happens with `jit_compile` under PyTorch 1.7\u001B[39;00m\n\u001B[1;32m    562\u001B[0m     args \u001B[38;5;241m=\u001B[39m [arg\u001B[38;5;241m.\u001B[39mdetach() \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mis_tensor(arg) \u001B[38;5;28;01melse\u001B[39;00m arg \u001B[38;5;28;01mfor\u001B[39;00m arg \u001B[38;5;129;01min\u001B[39;00m args]\n\u001B[0;32m--> 563\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m x, chain_id \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msampler\u001B[38;5;241m.\u001B[39mrun(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    564\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m num_samples[chain_id] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    565\u001B[0m             num_samples[chain_id] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/pyro/infer/mcmc/api.py:223\u001B[0m, in \u001B[0;36m_UnarySampler.run\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    221\u001B[0m logger \u001B[38;5;241m=\u001B[39m initialize_logger(logger, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m, progress_bar)\n\u001B[1;32m    222\u001B[0m hook_w_logging \u001B[38;5;241m=\u001B[39m _add_logging_hook(logger, progress_bar, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhook)\n\u001B[0;32m--> 223\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m sample \u001B[38;5;129;01min\u001B[39;00m _gen_samples(\n\u001B[1;32m    224\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel,\n\u001B[1;32m    225\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwarmup_steps,\n\u001B[1;32m    226\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples,\n\u001B[1;32m    227\u001B[0m     hook_w_logging,\n\u001B[1;32m    228\u001B[0m     i \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_chains \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;241m*\u001B[39margs,\n\u001B[1;32m    230\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m    231\u001B[0m ):\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m sample, i  \u001B[38;5;66;03m# sample, chain_id\u001B[39;00m\n\u001B[1;32m    233\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkernel\u001B[38;5;241m.\u001B[39mcleanup()\n",
      "File \u001B[0;32m~/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/pyro/infer/mcmc/api.py:150\u001B[0m, in \u001B[0;36m_gen_samples\u001B[0;34m(kernel, warmup_steps, num_samples, hook, chain_id, *args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;28;01myield\u001B[39;00m {name: params[name]\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;28;01mfor\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m save_params}\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(warmup_steps):\n\u001B[0;32m--> 150\u001B[0m     params \u001B[38;5;241m=\u001B[39m \u001B[43mkernel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m     hook(\n\u001B[1;32m    152\u001B[0m         kernel,\n\u001B[1;32m    153\u001B[0m         params,\n\u001B[1;32m    154\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWarmup [\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(chain_id) \u001B[38;5;28;01mif\u001B[39;00m chain_id \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWarmup\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    155\u001B[0m         i,\n\u001B[1;32m    156\u001B[0m     )\n\u001B[1;32m    157\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_samples):\n",
      "File \u001B[0;32m~/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/pyro/infer/mcmc/nuts.py:437\u001B[0m, in \u001B[0;36mNUTS.sample\u001B[0;34m(self, params)\u001B[0m\n\u001B[1;32m    433\u001B[0m direction \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(direction\u001B[38;5;241m.\u001B[39mitem())\n\u001B[1;32m    434\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    435\u001B[0m     direction \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    436\u001B[0m ):  \u001B[38;5;66;03m# go to the right, start from the right leaf of current tree\u001B[39;00m\n\u001B[0;32m--> 437\u001B[0m     new_tree \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_tree\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    438\u001B[0m \u001B[43m        \u001B[49m\u001B[43mz_right\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    439\u001B[0m \u001B[43m        \u001B[49m\u001B[43mr_right\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    440\u001B[0m \u001B[43m        \u001B[49m\u001B[43mz_right_grads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    441\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlog_slice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    442\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdirection\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    443\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtree_depth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    444\u001B[0m \u001B[43m        \u001B[49m\u001B[43menergy_current\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    445\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    446\u001B[0m     \u001B[38;5;66;03m# update leaf for the next doubling process\u001B[39;00m\n\u001B[1;32m    447\u001B[0m     z_right \u001B[38;5;241m=\u001B[39m new_tree\u001B[38;5;241m.\u001B[39mz_right\n",
      "File \u001B[0;32m~/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/pyro/infer/mcmc/nuts.py:281\u001B[0m, in \u001B[0;36mNUTS._build_tree\u001B[0;34m(self, z, r, z_grads, log_slice, direction, tree_depth, energy_current)\u001B[0m\n\u001B[1;32m    279\u001B[0m     r \u001B[38;5;241m=\u001B[39m half_tree\u001B[38;5;241m.\u001B[39mr_left\n\u001B[1;32m    280\u001B[0m     z_grads \u001B[38;5;241m=\u001B[39m half_tree\u001B[38;5;241m.\u001B[39mz_left_grads\n\u001B[0;32m--> 281\u001B[0m other_half_tree \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_tree\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    282\u001B[0m \u001B[43m    \u001B[49m\u001B[43mz\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mz_grads\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_slice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdirection\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtree_depth\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menergy_current\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    285\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_multinomial_sampling:\n\u001B[1;32m    286\u001B[0m     tree_weight \u001B[38;5;241m=\u001B[39m _logaddexp(half_tree\u001B[38;5;241m.\u001B[39mweight, other_half_tree\u001B[38;5;241m.\u001B[39mweight)\n",
      "File \u001B[0;32m~/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/pyro/infer/mcmc/nuts.py:281\u001B[0m, in \u001B[0;36mNUTS._build_tree\u001B[0;34m(self, z, r, z_grads, log_slice, direction, tree_depth, energy_current)\u001B[0m\n\u001B[1;32m    279\u001B[0m     r \u001B[38;5;241m=\u001B[39m half_tree\u001B[38;5;241m.\u001B[39mr_left\n\u001B[1;32m    280\u001B[0m     z_grads \u001B[38;5;241m=\u001B[39m half_tree\u001B[38;5;241m.\u001B[39mz_left_grads\n\u001B[0;32m--> 281\u001B[0m other_half_tree \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_tree\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    282\u001B[0m \u001B[43m    \u001B[49m\u001B[43mz\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mz_grads\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_slice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdirection\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtree_depth\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menergy_current\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    285\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_multinomial_sampling:\n\u001B[1;32m    286\u001B[0m     tree_weight \u001B[38;5;241m=\u001B[39m _logaddexp(half_tree\u001B[38;5;241m.\u001B[39mweight, other_half_tree\u001B[38;5;241m.\u001B[39mweight)\n",
      "File \u001B[0;32m~/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/pyro/infer/mcmc/nuts.py:254\u001B[0m, in \u001B[0;36mNUTS._build_tree\u001B[0;34m(self, z, r, z_grads, log_slice, direction, tree_depth, energy_current)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_build_tree\u001B[39m(\n\u001B[1;32m    251\u001B[0m     \u001B[38;5;28mself\u001B[39m, z, r, z_grads, log_slice, direction, tree_depth, energy_current\n\u001B[1;32m    252\u001B[0m ):\n\u001B[1;32m    253\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m tree_depth \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 254\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_build_basetree\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m            \u001B[49m\u001B[43mz\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mz_grads\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlog_slice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdirection\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menergy_current\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    258\u001B[0m     \u001B[38;5;66;03m# build the first half of tree\u001B[39;00m\n\u001B[1;32m    259\u001B[0m     half_tree \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_tree(\n\u001B[1;32m    260\u001B[0m         z, r, z_grads, log_slice, direction, tree_depth \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m, energy_current\n\u001B[1;32m    261\u001B[0m     )\n",
      "File \u001B[0;32m~/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/pyro/infer/mcmc/nuts.py:199\u001B[0m, in \u001B[0;36mNUTS._build_basetree\u001B[0;34m(self, z, r, z_grads, log_slice, direction, energy_current)\u001B[0m\n\u001B[1;32m    197\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_build_basetree\u001B[39m(\u001B[38;5;28mself\u001B[39m, z, r, z_grads, log_slice, direction, energy_current):\n\u001B[1;32m    198\u001B[0m     step_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep_size \u001B[38;5;28;01mif\u001B[39;00m direction \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m-\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep_size\n\u001B[0;32m--> 199\u001B[0m     z_new, r_new, z_grads, potential_energy \u001B[38;5;241m=\u001B[39m \u001B[43mvelocity_verlet\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    200\u001B[0m \u001B[43m        \u001B[49m\u001B[43mz\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    201\u001B[0m \u001B[43m        \u001B[49m\u001B[43mr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    202\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpotential_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    203\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmass_matrix_adapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkinetic_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    204\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstep_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    205\u001B[0m \u001B[43m        \u001B[49m\u001B[43mz_grads\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mz_grads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    206\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    207\u001B[0m     r_new_unscaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmass_matrix_adapter\u001B[38;5;241m.\u001B[39munscale(r_new)\n\u001B[1;32m    208\u001B[0m     energy_new \u001B[38;5;241m=\u001B[39m potential_energy \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_kinetic_energy(r_new_unscaled)\n",
      "File \u001B[0;32m~/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/pyro/ops/integrator.py:39\u001B[0m, in \u001B[0;36mvelocity_verlet\u001B[0;34m(z, r, potential_fn, kinetic_grad, step_size, num_steps, z_grads)\u001B[0m\n\u001B[1;32m     37\u001B[0m r_next \u001B[38;5;241m=\u001B[39m r\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_steps):\n\u001B[0;32m---> 39\u001B[0m     z_next, r_next, z_grads, potential_energy \u001B[38;5;241m=\u001B[39m \u001B[43m_single_step_verlet\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     40\u001B[0m \u001B[43m        \u001B[49m\u001B[43mz_next\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mr_next\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpotential_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkinetic_grad\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mz_grads\u001B[49m\n\u001B[1;32m     41\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m z_next, r_next, z_grads, potential_energy\n",
      "File \u001B[0;32m~/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/pyro/ops/integrator.py:61\u001B[0m, in \u001B[0;36m_single_step_verlet\u001B[0;34m(z, r, potential_fn, kinetic_grad, step_size, z_grads)\u001B[0m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m site_name \u001B[38;5;129;01min\u001B[39;00m z:\n\u001B[1;32m     59\u001B[0m     z[site_name] \u001B[38;5;241m=\u001B[39m z[site_name] \u001B[38;5;241m+\u001B[39m step_size \u001B[38;5;241m*\u001B[39m r_grads[site_name]  \u001B[38;5;66;03m# z(n+1)\u001B[39;00m\n\u001B[0;32m---> 61\u001B[0m z_grads, potential_energy \u001B[38;5;241m=\u001B[39m \u001B[43mpotential_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpotential_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mz\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m site_name \u001B[38;5;129;01min\u001B[39;00m r:\n\u001B[1;32m     63\u001B[0m     r[site_name] \u001B[38;5;241m=\u001B[39m r[site_name] \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m0.5\u001B[39m \u001B[38;5;241m*\u001B[39m step_size \u001B[38;5;241m*\u001B[39m (\u001B[38;5;241m-\u001B[39mz_grads[site_name])  \u001B[38;5;66;03m# r(n+1)\u001B[39;00m\n",
      "File \u001B[0;32m~/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/pyro/ops/integrator.py:91\u001B[0m, in \u001B[0;36mpotential_grad\u001B[0;34m(potential_fn, z)\u001B[0m\n\u001B[1;32m     89\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     90\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[0;32m---> 91\u001B[0m grads \u001B[38;5;241m=\u001B[39m \u001B[43mgrad\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpotential_energy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mz_nodes\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m node \u001B[38;5;129;01min\u001B[39;00m z_nodes:\n\u001B[1;32m     93\u001B[0m     node\u001B[38;5;241m.\u001B[39mrequires_grad_(\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/torch/autograd/__init__.py:300\u001B[0m, in \u001B[0;36mgrad\u001B[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001B[0m\n\u001B[1;32m    298\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _vmap_internals\u001B[38;5;241m.\u001B[39m_vmap(vjp, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m0\u001B[39m, allow_none_pass_through\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)(grad_outputs_)\n\u001B[1;32m    299\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 300\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    301\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_outputs_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    302\u001B[0m \u001B[43m        \u001B[49m\u001B[43mallow_unused\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# categorical/multinomial distribution\n",
    "\n",
    "# uniform prior\n",
    "prior_counts = torch.ones((2,2))\n",
    "\n",
    "\n",
    "#model\n",
    "def model(data):\n",
    "    prior = pyro.sample(\"prior\", dist.Dirichlet(prior_counts))\n",
    "    total_counts = int(data.sum())\n",
    "    pyro.sample(\"likelihood\", dist.Multinomial(total_counts, prior), obs=data)\n",
    "\n",
    "\n",
    "nuts_kernel = NUTS(model)\n",
    "num_samples, warmup_steps = (300, 200)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=num_samples, warmup_steps=warmup_steps, disable_progbar=True)\n",
    "all_means = []\n",
    "\n",
    "# sampling\n",
    "for i in range(len(counter)):\n",
    "    mcmc.run(counter[i])\n",
    "    hmc_samples = {k: v.detach().cpu().numpy()\n",
    "                   for k, v in mcmc.get_samples().items()}\n",
    "    means = hmc_samples['prior'].mean(axis=0)\n",
    "    stds = hmc_samples['prior'].std(axis=0)\n",
    "    print('observation: ', df_rational[i])\n",
    "    print('probabilities: ', means)\n",
    "    all_means.append(means)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analysis sliding window K"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "k_wind = [2, 5, 10, 25, 50, 100, 150]\n",
    "HAB_TRIALS = 16\n",
    "\n",
    "path_sias = 'data/sias_score.csv'\n",
    "path_lds = 'data/lds_subjects.csv'\n",
    "\n",
    "len_sub = 6\n",
    "top_lds = anxious_subjects(path_lds, len_sub, 'top')\n",
    "bot_lds = anxious_subjects(path_lds, len_sub, 'bot')\n",
    "\n",
    "top_sias = anxious_subjects(path_sias, len_sub)\n",
    "bot_sias = anxious_subjects(path_sias, len_sub, 'bot')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "df_correlation = pd.DataFrame(columns=['subject','k','pearson','r2score','person_disc','cohen_disc'])\n",
    "\n",
    "for k in list(k_wind):\n",
    "\n",
    "    # read output of the rational model with different K\n",
    "    array_csplus_simulated = np.load('output/pyro/sliding_wind/k'+str(k)+'_csplus.npy',allow_pickle=True)\n",
    "    array_csminus_simulated = np.load('output/pyro/sliding_wind/k'+str(k)+'_csminus.npy',allow_pickle=True)\n",
    "    total_array_simulated = np.load('output/pyro/sliding_wind/k'+str(k)+'_total.npy',allow_pickle=True)\n",
    "\n",
    "    rating_rational_subj = total_array_simulated[HAB_TRIALS:] #remove habituation trials\n",
    "\n",
    "\n",
    "    for sub in valid_sub:\n",
    "        subj_ = extract_correct_csv.read_correct_subject_csv(sub)\n",
    "\n",
    "        #read data of real subjects\n",
    "        df_sub = pd.read_csv('data/newLookAtMe/newLookAtMe'+subj_+'.csv')\n",
    "        df_sub = df_sub[['shock', 'rating', 'morphing level']]\n",
    "        df_sub['shock'] = df_sub['shock'].astype(int) #convert shock from boolean to int\n",
    "        df_sub['morphing level'] = [int(d == 6) for d in df_sub['morphing level']]\n",
    "        df_sub['rating'] = df_sub['rating'].replace([1, 2, 3, 4, 5], [0.2, 0.4, 0.6, 0.8, 1]) #convert vote into (0,1)\n",
    "        df_sub_learn = df_sub[HAB_TRIALS:] #remove habituation trials\n",
    "        rating_sub = np.array(df_sub_learn['rating'])\n",
    "\n",
    "        rating_rational = rating_rational_subj\n",
    "        #remove trial from rating agent simulation and real data if in one list is nan\n",
    "        bad = ~np.logical_or(np.isnan(rating_sub), np.isnan(rating_rational))\n",
    "        rating_sub = np.compress(bad, rating_sub)\n",
    "        rating_rational = np.compress(bad, rating_rational)\n",
    "\n",
    "        #discretization of rating rational\n",
    "        round_vector = np.array([0.2, 0.4, 0.6, 0.8, 1])\n",
    "        rating_rational_discr = np.round(rating_rational / 0.2) * 0.2\n",
    "        rating_rational_discr = np.clip(rating_rational_discr, round_vector.min(), round_vector.max())\n",
    "\n",
    "        # calculate pearson correlation coefficient between k-rational model and real data\n",
    "        pearson = round(np.corrcoef(rating_sub,rating_rational)[0][1],2)\n",
    "\n",
    "        # calculate r2 score between k-rational model and real data\n",
    "        r2 = round(r2_score(rating_sub,rating_rational),2)\n",
    "\n",
    "        # calculate pearson correlation coefficient between k-rational model and real data using discrete values for k-rational model\n",
    "        pearson_disc = round(np.corrcoef(rating_sub,rating_rational_discr)[0][1],2)\n",
    "\n",
    "        # calculate cohen kappa between k-rational model and real data using discrete values for k-rational model\n",
    "        cohen_disc = round(cohen_kappa_score(rating_sub*10,rating_rational_discr*10),2)\n",
    "\n",
    "        # write line\n",
    "        df_tmp = pd.DataFrame({'subject':sub,'k':k,'pearson':pearson,'r2score':r2,'person_disc':pearson_disc,'cohen_disc':cohen_disc},index=np.arange(1))\n",
    "        df_correlation = pd.concat([df_correlation,df_tmp])\n",
    "\n",
    "df_correlation['subject'] = [float(x) for x in df_correlation['subject']] #convert subjects into float\n",
    "\n",
    "# read social anxiety values\n",
    "sias_df = pd.read_csv('data/sias_score.csv').drop(columns='social_anxiety')\n",
    "sias_df['subject'] = [float(x) for x in sias_df['subject']] #convert subjects into float\n",
    "\n",
    "# read linear deviation score (how much this subject do fear generalization)\n",
    "lds_df = pd.read_csv('data/lds_subjects.csv')\n",
    "lds_df['subject'] = [float(x) for x in lds_df['subject']] #convert subjects into float"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# one dataframe with social anxiety, linear devation score and correlation measures for each subject\n",
    "res = pd.merge(sias_df, lds_df)\n",
    "df_correlation = pd.merge(res,df_correlation).dropna().reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "     subject  sias_score    lds    k  pearson  r2score  person_disc  \\\n0        1.0        21.0  0.201    2     0.24    -1.54         0.27   \n1        1.0        21.0  0.201    5     0.30    -2.35         0.30   \n2        1.0        21.0  0.201   10     0.29    -3.22         0.28   \n3        1.0        21.0  0.201   25     0.26    -4.27         0.23   \n4        1.0        21.0  0.201   50     0.23    -4.78         0.22   \n..       ...         ...    ...  ...      ...      ...          ...   \n205     54.0        17.0  1.594   10     0.87     0.03         0.83   \n206     54.0        17.0  1.594   25     0.89    -0.14         0.87   \n207     54.0        17.0  1.594   50     0.90    -0.27         0.85   \n208     54.0        17.0  1.594  100     0.91    -0.31         0.85   \n209     54.0        17.0  1.594  150     0.91    -0.35         0.84   \n\n     cohen_disc  \n0          0.00  \n1          0.06  \n2          0.03  \n3          0.00  \n4         -0.01  \n..          ...  \n205        0.16  \n206        0.14  \n207        0.14  \n208        0.14  \n209        0.13  \n\n[210 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject</th>\n      <th>sias_score</th>\n      <th>lds</th>\n      <th>k</th>\n      <th>pearson</th>\n      <th>r2score</th>\n      <th>person_disc</th>\n      <th>cohen_disc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>21.0</td>\n      <td>0.201</td>\n      <td>2</td>\n      <td>0.24</td>\n      <td>-1.54</td>\n      <td>0.27</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>21.0</td>\n      <td>0.201</td>\n      <td>5</td>\n      <td>0.30</td>\n      <td>-2.35</td>\n      <td>0.30</td>\n      <td>0.06</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>21.0</td>\n      <td>0.201</td>\n      <td>10</td>\n      <td>0.29</td>\n      <td>-3.22</td>\n      <td>0.28</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>21.0</td>\n      <td>0.201</td>\n      <td>25</td>\n      <td>0.26</td>\n      <td>-4.27</td>\n      <td>0.23</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>21.0</td>\n      <td>0.201</td>\n      <td>50</td>\n      <td>0.23</td>\n      <td>-4.78</td>\n      <td>0.22</td>\n      <td>-0.01</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>205</th>\n      <td>54.0</td>\n      <td>17.0</td>\n      <td>1.594</td>\n      <td>10</td>\n      <td>0.87</td>\n      <td>0.03</td>\n      <td>0.83</td>\n      <td>0.16</td>\n    </tr>\n    <tr>\n      <th>206</th>\n      <td>54.0</td>\n      <td>17.0</td>\n      <td>1.594</td>\n      <td>25</td>\n      <td>0.89</td>\n      <td>-0.14</td>\n      <td>0.87</td>\n      <td>0.14</td>\n    </tr>\n    <tr>\n      <th>207</th>\n      <td>54.0</td>\n      <td>17.0</td>\n      <td>1.594</td>\n      <td>50</td>\n      <td>0.90</td>\n      <td>-0.27</td>\n      <td>0.85</td>\n      <td>0.14</td>\n    </tr>\n    <tr>\n      <th>208</th>\n      <td>54.0</td>\n      <td>17.0</td>\n      <td>1.594</td>\n      <td>100</td>\n      <td>0.91</td>\n      <td>-0.31</td>\n      <td>0.85</td>\n      <td>0.14</td>\n    </tr>\n    <tr>\n      <th>209</th>\n      <td>54.0</td>\n      <td>17.0</td>\n      <td>1.594</td>\n      <td>150</td>\n      <td>0.91</td>\n      <td>-0.35</td>\n      <td>0.84</td>\n      <td>0.13</td>\n    </tr>\n  </tbody>\n</table>\n<p>210 rows Ã— 8 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_correlation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check from this if there's something useful"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Rational agent discretisation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "valid_subjects = extract_correct_csv.extract_only_valid_subject()\n",
    "len(valid_subjects)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_array_simulated = np.load('output/pyro/complete_rational/total.npy',allow_pickle=True)\n",
    "total_array_simulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "values = np.array([0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "discretized_data = np.digitize(total_array_simulated, values)\n",
    "print(discretized_data.shape)\n",
    "\n",
    "\n",
    "df_global = pd.DataFrame(columns=['Subject', 'Rating rational', 'Rating real'])\n",
    "\n",
    "for sub in valid_subjects:\n",
    "    string_sub = extract_correct_csv.read_correct_subject_csv(sub)\n",
    "    df_sub = pd.read_csv('data/newLookAtMe/newLookAtMe'+string_sub+'.csv')\n",
    "    df_sub = df_sub[16:]\n",
    "    tmp_df = pd.DataFrame({'Subject': sub, 'Rating rational': discretized_data, 'Rating real': df_sub['rating']})\n",
    "    df_global = pd.concat([df_global, tmp_df])\n",
    "\n",
    "df_global = df_global.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "valid_subjects = df_global.Subject.unique()\n",
    "valid_subjects"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dict_results = {}\n",
    "for x in valid_subjects:\n",
    "    df_sub_ = df_global[df_global.Subject == x].dropna().drop(columns=['Subject']).reset_index(drop=True)\n",
    "    df_sub_['Rating rational'] = df_sub_['Rating rational'].astype(float)\n",
    "    result = intraclass_correlation(df_sub_).value\n",
    "    dict_results[x] = result\n",
    "\n",
    "dict_results\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_icc = pd.DataFrame(list(dict_results.items()), columns=['Subject', 'ICC'])\n",
    "df_icc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_sias = 'data/sias_score.csv'\n",
    "path_lds = 'data/lds_subjects.csv'\n",
    "\n",
    "len_sub = 6\n",
    "top_lds = anxious_subjects(path_lds, len_sub, 'top')\n",
    "bot_lds = anxious_subjects(path_lds, len_sub, 'bot')\n",
    "\n",
    "top_sias = anxious_subjects(path_sias, len_sub)\n",
    "bot_sias = anxious_subjects(path_sias, len_sub, 'bot')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_top_sias = df_icc[df_icc.Subject.isin(top_sias)]['ICC'].mean()\n",
    "mean_bot_sias = df_icc[df_icc.Subject.isin(bot_sias)]['ICC'].mean()\n",
    "mean_top_lds = df_icc[df_icc.Subject.isin(top_lds)]['ICC'].mean()\n",
    "mean_bot_lds = df_icc[df_icc.Subject.isin(bot_lds)]['ICC'].mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Average of the first {len_sub} subjects with higher sias score: {round(mean_top_sias, 2)}')\n",
    "print(f'Average of the first {len_sub} subjects with lower sias score: {round(mean_bot_sias, 2)}')\n",
    "print(f'Average of the first {len_sub} subjects with higher linear deviation score: {round(mean_top_lds,2)}')\n",
    "print(f'Average of the first {len_sub} subjects with lower linear deviation score: {round(mean_bot_lds, 2)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
