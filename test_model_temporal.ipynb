{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "PPCA lavora con più variabili osservabili anzichè una sola"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (aesara.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pymc as pm\n",
    "import matplotlib.pyplot as plt\n",
    "import aesara.tensor as at\n",
    "import arviz as az\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics as metrics\n",
    "from scipy import stats\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import warnings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# extract data social anxiety"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "csv_ = '/Users/marcoghezzi/PycharmProjects/pythonProject/osfstorage-archive/behavior/LookAtMe_045.csv'\n",
    "csv_ = '/home/paolo/matteo/matteo/unimi/tesi_master/code/osfstorage-archive/behavior/LookAtMe_045.csv'\n",
    "global_data = pd.read_csv(csv_, sep='\\t')\n",
    "y = np.array(list([int(d>2) for d in global_data['rating']]))\n",
    "e_labels = y[:,np.newaxis]  # rating > 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 1\n"
     ]
    }
   ],
   "source": [
    "N_e = e_labels.shape[0]\n",
    "D_e = e_labels.shape[1]\n",
    "print(N_e,D_e)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## test with new data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Loading EDA for subject 45 and all sessions from dataset FEAR\n",
      ">> Loading HR for subject 45 and all sessions from dataset FEAR\n",
      ">> Loading PUPIL for subject 45 and all sessions from dataset FEAR\n",
      ">> Processing EDA ...\n",
      ">> Extracting wavelet features from EDA signal, adopting (2, 1) window ...\n",
      ">> Processing HR ... using neurokit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/paolo/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Extracting wavelet features from HR signal, adopting (2, 1) window ...\n",
      ">> Extracting mean features from PUPIL signal, adopting (1, 0) window ...\n"
     ]
    }
   ],
   "source": [
    "from deepemogp import feature_extractor\n",
    "from deepemogp.signal import physio as physio\n",
    "from deepemogp import datasets as datasets\n",
    "from deepemogp.signal import behavior as behavior\n",
    "from deepemogp.signal.physio import ecg\n",
    "# from: https://github.com/SheffieldML/GPy\n",
    "#import GPy\n",
    "# from: https://github.com/SheffieldML/PyDeepGP\n",
    "#import deepgp\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "show = False\n",
    "# definition of the feature extractors to be used later\n",
    "f2 = feature_extractor.FE('wavelet', window=(2, 1))\n",
    "f3 = feature_extractor.FE('mean', window=(1,0))\n",
    "\n",
    "# definition of the physiological signals to be extracted\n",
    "eda_ = physio.EDA(f2)\n",
    "hr_ = physio.HR(f2)\n",
    "pupil_ = behavior.PUPIL(f3)\n",
    "\n",
    "# definition of the emotional annotation to be extracted\n",
    "#va = annotation.VA('valence', f3)\n",
    "#ar = annotation.VA('arousal', f3)\n",
    "# extraction of the desired data from the dataset\n",
    "d = datasets.FEAR(signals={hr_,pupil_,eda_}, subjects={'45'})\n",
    "\n",
    "for s in d.signals:\n",
    "    # preprocess ...\n",
    "    if s.name =='EDA':\n",
    "        s.preprocess(show=show,new_fps=500)\n",
    "        s.feature_ext.extract_feat(s,show=show)\n",
    "    else:\n",
    "        if s.name == 'HR':\n",
    "            list_hr_test = s.raw[0]['data']\n",
    "            s.preprocess(show=show, useneurokit=True)\n",
    "            s.feature_ext.extract_feat(s,show=show)\n",
    "\n",
    "        else:\n",
    "            s.feature_ext.extract_feat_without_preprocess(s, show=show)\n",
    "\n",
    "    #add feature extraction for eda before preprocessing\n",
    "\n",
    "    # ... and extract features from each signal type\n",
    "\n",
    "\n",
    "for sig in d.signals:\n",
    "    if sig.name=='EDA':\n",
    "        eda_data = sig.features\n",
    "    if sig.name=='HR':\n",
    "        hr_data = sig.features\n",
    "    if sig.name=='PUPIL':\n",
    "        pupil_data = sig.features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "TRIAL = 160"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "hr =np.array(hr_data)\n",
    "hr = hr.reshape((TRIAL, int(hr.shape[0]/TRIAL*hr.shape[1])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "pupil = np.array(pupil_data)\n",
    "pupil = pupil.reshape((TRIAL, int(pupil.shape[0]/TRIAL*pupil.shape[1])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "eda = np.array(eda_data)\n",
    "eda = eda.reshape((TRIAL,int(eda.shape[0]/TRIAL*eda.shape[1])))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## end test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "prendo un'implementazione di sppca e la applico al nostro caso"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "different types of observable data\n",
    "\n",
    "1) gaze\n",
    "2) fisio\n",
    "    2.1) heart rate variability\n",
    "    2.2) eda phasic value\n",
    "3) social anxiety\n",
    "4) aspettativa del dolore"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "\"social_anx = data['social anxiety'][:,np.newaxis]\\npain_exp = data['pain expectation'][:,np.newaxis]\""
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''social_anx = data['social anxiety'][:,np.newaxis]\n",
    "pain_exp = data['pain expectation'][:,np.newaxis]'''\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 5\n",
      "160 60\n",
      "160 60\n",
      "160 1\n"
     ]
    }
   ],
   "source": [
    "N_pupil = pupil.shape[0]\n",
    "D_pupil = pupil.shape[1]\n",
    "\n",
    "N_hr = hr.shape[0]\n",
    "D_hr = hr.shape[1]\n",
    "\n",
    "N_eda = eda.shape[0]\n",
    "D_eda = eda.shape[1]\n",
    "K = 3\n",
    "\n",
    "print(N_pupil,D_pupil)\n",
    "print(N_hr,D_hr)\n",
    "print(N_eda,D_eda)\n",
    "print(N_e, D_e)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1507.82432239, 1507.82432239, 1507.82432239, ..., 1566.0845009 ,\n        1520.02818112, 1518.7678512 ],\n       [1561.94779093, 1561.94779093, 1561.94779093, ..., 1513.92693106,\n        1511.8541424 , 1511.8541424 ],\n       [1552.65898888, 1552.65898888, 1552.65898888, ..., 1478.91710429,\n        1478.91614366, 1478.91614366],\n       ...,\n       [1513.53959853, 1513.53959853, 1513.53959853, ..., 1475.70110856,\n        1475.70110856, 1475.70110856],\n       [1562.66691975, 1562.66691975, 1562.66691975, ..., 1694.83054188,\n        1731.68433009, 1731.6894679 ],\n       [1539.28006789, 1539.28006789, 1539.28006789, ..., 1445.25223889,\n        1441.56087692, 1441.25889603]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "ShapeError",
     "evalue": "Dimensionality of data and RV don't match. (actual 2 != expected 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mShapeError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [14], line 27\u001B[0m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# dati dell'hrv interpretati come una gaussiana\u001B[39;00m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m#x_hr = pm.Normal('x_hr', mu=Whr.dot(c.T), sigma=at.ones([D_hr,N_hr]) ,shape=[D_hr, N_hr], observed=hr_data)\u001B[39;00m\n\u001B[1;32m     26\u001B[0m sigma_hr \u001B[38;5;241m=\u001B[39m pm\u001B[38;5;241m.\u001B[39mExponential(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msigma_hr\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m50.0\u001B[39m)\n\u001B[0;32m---> 27\u001B[0m x_hr \u001B[38;5;241m=\u001B[39m pm\u001B[38;5;241m.\u001B[39mGaussianRandomWalk(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx_hr\u001B[39m\u001B[38;5;124m'\u001B[39m,sigma\u001B[38;5;241m=\u001B[39msigma_hr,init_dist \u001B[38;5;241m=\u001B[39m pm\u001B[38;5;241m.\u001B[39mNormal\u001B[38;5;241m.\u001B[39mdist(mu\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,sigma\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m),observed\u001B[38;5;241m=\u001B[39mhr_data,dims\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime_hr\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     28\u001B[0m \u001B[38;5;66;03m# dati della dilatazione pupille interpretati come una gaussiana\u001B[39;00m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m#x_pupil = pm.Normal('x_pupil', mu=Wpupil.dot(c.T), sigma=at.ones([D_pupil, N_pupil]), shape=[D_pupil, N_pupil], observed=pupil_data)\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m#eda\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m# due strade: binary o multiclass (1-4)\u001B[39;00m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;66;03m# p = probability of success?\u001B[39;00m\n\u001B[1;32m     36\u001B[0m x_e \u001B[38;5;241m=\u001B[39m pm\u001B[38;5;241m.\u001B[39mBernoulli(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx_e\u001B[39m\u001B[38;5;124m'\u001B[39m , p\u001B[38;5;241m=\u001B[39mpm\u001B[38;5;241m.\u001B[39mmath\u001B[38;5;241m.\u001B[39msigmoid(We\u001B[38;5;241m.\u001B[39mdot(c\u001B[38;5;241m.\u001B[39mT)) , shape \u001B[38;5;241m=\u001B[39m[D_e, N_e], observed\u001B[38;5;241m=\u001B[39me_data)\n",
      "File \u001B[0;32m~/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/pymc/distributions/timeseries.py:246\u001B[0m, in \u001B[0;36mPredefinedRandomWalk.__new__\u001B[0;34m(cls, name, *args, **kwargs)\u001B[0m\n\u001B[1;32m    244\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__new__\u001B[39m(\u001B[38;5;28mcls\u001B[39m, name, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    245\u001B[0m     init_dist, innovation_dist, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mget_dists(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 246\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mRandomWalk\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit_dist\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minit_dist\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minnovation_dist\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minnovation_dist\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/pymc/distributions/timeseries.py:84\u001B[0m, in \u001B[0;36mRandomWalk.__new__\u001B[0;34m(cls, innovation_dist, steps, *args, **kwargs)\u001B[0m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__new__\u001B[39m(\u001B[38;5;28mcls\u001B[39m, \u001B[38;5;241m*\u001B[39margs, innovation_dist, steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     76\u001B[0m     steps \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mget_steps(\n\u001B[1;32m     77\u001B[0m         innovation_dist\u001B[38;5;241m=\u001B[39minnovation_dist,\n\u001B[1;32m     78\u001B[0m         steps\u001B[38;5;241m=\u001B[39msteps,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     81\u001B[0m         observed\u001B[38;5;241m=\u001B[39mkwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mobserved\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m     82\u001B[0m     )\n\u001B[0;32m---> 84\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__new__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minnovation_dist\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minnovation_dist\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msteps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/pymc/distributions/distribution.py:292\u001B[0m, in \u001B[0;36mDistribution.__new__\u001B[0;34m(cls, name, rng, dims, initval, observed, total_size, transform, *args, **kwargs)\u001B[0m\n\u001B[1;32m    288\u001B[0m         kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshape\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(observed\u001B[38;5;241m.\u001B[39mshape)\n\u001B[1;32m    290\u001B[0m rv_out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mdist(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 292\u001B[0m rv_out \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mregister_rv\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    293\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrv_out\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    294\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    295\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobserved\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    296\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtotal_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    297\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdims\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdims\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    298\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtransform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    299\u001B[0m \u001B[43m    \u001B[49m\u001B[43minitval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    300\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    302\u001B[0m \u001B[38;5;66;03m# add in pretty-printing support\u001B[39;00m\n\u001B[1;32m    303\u001B[0m rv_out\u001B[38;5;241m.\u001B[39mstr_repr \u001B[38;5;241m=\u001B[39m types\u001B[38;5;241m.\u001B[39mMethodType(str_for_dist, rv_out)\n",
      "File \u001B[0;32m~/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/pymc/model.py:1386\u001B[0m, in \u001B[0;36mModel.register_rv\u001B[0;34m(self, rv_var, name, data, total_size, dims, transform, initval)\u001B[0m\n\u001B[1;32m   1379\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[1;32m   1380\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mVariables that depend on other nodes cannot be used for observed data.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1381\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe data variable was: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdata\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1382\u001B[0m         )\n\u001B[1;32m   1384\u001B[0m     \u001B[38;5;66;03m# `rv_var` is potentially changed by `make_obs_var`,\u001B[39;00m\n\u001B[1;32m   1385\u001B[0m     \u001B[38;5;66;03m# for example into a new graph for imputation of missing data.\u001B[39;00m\n\u001B[0;32m-> 1386\u001B[0m     rv_var \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_obs_var\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrv_var\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1388\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m rv_var\n",
      "File \u001B[0;32m~/matteo/matteo/unimi/tesi_master/code/my_env/lib/python3.8/site-packages/pymc/model.py:1412\u001B[0m, in \u001B[0;36mModel.make_obs_var\u001B[0;34m(self, rv_var, data, dims, transform)\u001B[0m\n\u001B[1;32m   1409\u001B[0m data \u001B[38;5;241m=\u001B[39m convert_observed_data(data)\u001B[38;5;241m.\u001B[39mastype(rv_var\u001B[38;5;241m.\u001B[39mdtype)\n\u001B[1;32m   1411\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m data\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m!=\u001B[39m rv_var\u001B[38;5;241m.\u001B[39mndim:\n\u001B[0;32m-> 1412\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ShapeError(\n\u001B[1;32m   1413\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDimensionality of data and RV don\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt match.\u001B[39m\u001B[38;5;124m\"\u001B[39m, actual\u001B[38;5;241m=\u001B[39mdata\u001B[38;5;241m.\u001B[39mndim, expected\u001B[38;5;241m=\u001B[39mrv_var\u001B[38;5;241m.\u001B[39mndim\n\u001B[1;32m   1414\u001B[0m     )\n\u001B[1;32m   1416\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m aesara\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mcompute_test_value \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moff\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   1417\u001B[0m     test_value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(rv_var\u001B[38;5;241m.\u001B[39mtag, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_value\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[0;31mShapeError\u001B[0m: Dimensionality of data and RV don't match. (actual 2 != expected 1)"
     ]
    }
   ],
   "source": [
    "with pm.Model(coords={'time_hr': hr[0]}) as sPPCA:\n",
    "    #dati osservabili\n",
    "    hr_data = pm.MutableData(\"hr_data\", hr.T)\n",
    "\n",
    "    #pupil_data = pm.MutableData(\"pupil_data\", pupil.T)\n",
    "\n",
    "    #eda_data = pm.MutableData(\"eda_data\", eda.T)\n",
    "\n",
    "    e_data = pm.ConstantData(\"e_data\", e_labels.T)\n",
    "\n",
    "    #matrici pesi\n",
    "    Whr = pm.Normal('Whr', mu=at.zeros([D_hr, K]), sigma=2.0 * at.ones([D_hr, K]), shape=[D_hr, K])\n",
    "    #Wpupil = pm.Normal('Wpupil', mu=at.zeros([D_pupil, K]), sigma=2.0 * at.ones([D_pupil, K]), shape=[D_pupil, K])\n",
    "\n",
    "    #Weda = pm.Normal('Weda', mu=at.zeros([D_eda, K]), sigma=2.0 * at.ones([D_eda, K]), shape=[D_eda, K])\n",
    "\n",
    "    #weight matrix for pain expectation.\n",
    "    #check mu,sigma,shape\n",
    "    We = pm.Normal('W_e', mu=at.zeros([D_e, K]), sigma=2.0 * at.ones([D_e,K]), shape=[D_e, K])\n",
    "\n",
    "    #latent space\n",
    "    c = pm.Normal('c', mu=at.zeros([N_hr,K]), sigma=at.ones([N_hr,K]), shape=[N_hr,K])\n",
    "\n",
    "    # dati dell'hrv interpretati come una gaussiana\n",
    "    #x_hr = pm.Normal('x_hr', mu=Whr.dot(c.T), sigma=at.ones([D_hr,N_hr]) ,shape=[D_hr, N_hr], observed=hr_data)\n",
    "    sigma_hr = pm.Exponential(\"sigma_hr\", 50.0)\n",
    "    x_hr = pm.GaussianRandomWalk('x_hr',sigma=sigma_hr,init_dist = pm.Normal.dist(mu=0,sigma=10),observed=hr_data,dims='time_hr')\n",
    "    # dati della dilatazione pupille interpretati come una gaussiana\n",
    "    #x_pupil = pm.Normal('x_pupil', mu=Wpupil.dot(c.T), sigma=at.ones([D_pupil, N_pupil]), shape=[D_pupil, N_pupil], observed=pupil_data)\n",
    "    #eda\n",
    "    #x_eda = pm.Normal('x_eda',mu=Weda.dot(c.T),sigma= at.ones([D_eda,N_pupil]), shape=[D_eda,N_eda], observed=eda_data)\n",
    "\n",
    "    # pain expectation. ciò che dovremmo inferire dato c\n",
    "    # due strade: binary o multiclass (1-4)\n",
    "    # p = probability of success?\n",
    "    x_e = pm.Bernoulli('x_e' , p=pm.math.sigmoid(We.dot(c.T)) , shape =[D_e, N_e], observed=e_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gv = pm.model_to_graphviz(sPPCA)\n",
    "gv.view()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sPPCA.free_RVs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "with sPPCA:\n",
    "    approx = pm.fit(100000, callbacks=[pm.callbacks.CheckParametersConvergence(tolerance=1e-4)])\n",
    "    trace = approx.sample(500)\n",
    "'''\n",
    "with sPPCA:\n",
    "    trace = pm.sample(1000,init='advi+adapt_diag',chains=1,target_accept=0.95)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#az.plot_posterior(mean_field.sample(1000), color=\"LightSeaGreen\")\n",
    "az.plot_trace(trace)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with sPPCA:\n",
    "    # update values of predictors:\n",
    "    pm.set_data({\"pupil_data\": pupil,\"hr_data\":hr,\"eda_data\":eda})\n",
    "    # use the updated values and predict outcomes and probabilities:\n",
    "    posterior_predictive = pm.sample_posterior_predictive(\n",
    "        trace, random_seed=123)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "e_pred = posterior_predictive.posterior_predictive[\"x_e\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "e_pred_mode = np.squeeze(stats.mode(e_pred[0], keepdims=False)[0])[:,np.newaxis]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "e_pred_mode"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "e_labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_accuracy_exp = accuracy_score(e_labels, e_pred_mode)\n",
    "print('\\n\\tTrain Accuracy Pain Expectation: ' + str(train_accuracy_exp))\n",
    "print(' ')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "--------------------------------------------------------------------------------------------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hr_pred_mean = (stats.median_abs_deviation(hr_pred[0]))[0]\n",
    "hr_pred_mean"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hr[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#hr_pred_mode= pd.Series([0.006,0.01,0.02,0.003])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "hr and hr_pred_mode devono avere same shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_accuracy_hr = (np.subtract(hr[0], hr_pred_mean))\n",
    "print('\\n\\t avg distance hr: \\n' + str(train_accuracy_hr))\n",
    "#print(' ')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with sPPCA:\n",
    "    # update values of predictors:\n",
    "    pm.set_data({\"hr_data\": hr})\n",
    "    # use the updated values and predict outcomes and probabilities:\n",
    "    posterior_predictive = pm.sample_posterior_predictive(\n",
    "        trace, random_seed=123)\n",
    "    gaze_pred = posterior_predictive.posterior_predictive[\"x_gaze\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gaze_pred"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gaze_pred_mean = np.mean(gaze_pred, axis=0).T.reshape(-1)\n",
    "gaze_true = pupil.reshape(-1)\n",
    "reconstructed_r2 = metrics.r2_score(gaze_true, gaze_pred_mean)\n",
    "\n",
    "print('\\n\\tReconstructed X R2 score: ' + str(reconstructed_r2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import deepemogp.feature_extractor as feature_extractor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f = feature_extractor.FE('wavelet', window=(8,6), params={'w_mother':'db3','w_maxlev':1})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = [3, 7, 1, 1, -2, 5, 4, 6]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f.apply(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
