{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import optuna as optuna\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import extract_correct_csv\n",
    "from tqdm import tqdm\n",
    "scaler = StandardScaler()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## logistic regression with sklearn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "[1,\n 2,\n 4,\n 5,\n 6,\n 7,\n 13,\n 15,\n 16,\n 17,\n 21,\n 22,\n 23,\n 26,\n 27,\n 28,\n 31,\n 32,\n 33,\n 41,\n 43,\n 44,\n 45,\n 46,\n 47,\n 48,\n 50,\n 51,\n 52,\n 54]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_subject = extract_correct_csv.extract_only_valid_subject()\n",
    "if 49 in valid_subject:\n",
    "    valid_subject.remove(49)\n",
    "valid_subject"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = ['subject', 'feature','fold', 'train accuracy', 'test accuracy']\n",
    "results = pd.DataFrame(columns = columns)\n",
    "index = 1\n",
    "for x in valid_subject:\n",
    "\n",
    "\n",
    "\n",
    "    types_ = ['hr', 'eda', 'pupil']\n",
    "    for type_ in types_:\n",
    "        X = pd.read_csv('data/features_4_2/'+type_+'/45.csv')\n",
    "        X = X[48:]\n",
    "        X = scaler.fit_transform(X)\n",
    "        # creating train and test\n",
    "        X = pd.DataFrame(X)\n",
    "        X = X.reset_index().drop(columns=('index'))\n",
    "\n",
    "\n",
    "\n",
    "        sss = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=123)\n",
    "\n",
    "        for i, (train_index, test_index) in enumerate(sss.split(X, y)):\n",
    "            y = pd.DataFrame(y)\n",
    "            y = y.reset_index().drop(columns=('index'))\n",
    "\n",
    "            N_train = len(train_index)\n",
    "            X_train = X.iloc[train_index, :]\n",
    "            y_train =y.iloc[train_index, :]\n",
    "\n",
    "            X_test = X.iloc[test_index, :]\n",
    "            y_test =y.iloc[test_index, :]\n",
    "\n",
    "            clf = LogisticRegression(random_state=123,max_iter=10000)\n",
    "            clf.fit(X_train, np.squeeze(np.array(y_train)))\n",
    "\n",
    "            train_ = clf.score(X_train, y_train)\n",
    "            test_ = clf.score(X_test, y_test)\n",
    "            dict_ = {'subject': x, 'feature': type_,'fold':int(i), 'train accuracy': train_, 'test accuracy': test_}\n",
    "            results = pd.concat([results, pd.DataFrame(data=dict_, index=np.arange(1))], ignore_index=True)\n",
    "            index = index + 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## accuracy logistic classifier sklearn monophysio"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reg_mono = results\n",
    "reg_mono"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "columns = ['subject', 'fold']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_regr=reg_mono.drop(columns=columns).groupby(by='feature', as_index=False).mean()\n",
    "var_regr=reg_mono.drop(columns=columns).groupby(by='feature', as_index=False).var()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## mean accuracy over all subjs logistic classifier sklearn monophysio"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_regr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## var over all subjs logistic classifier sklearn monophysio\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "var_regr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Multi physio classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subjects = extract_correct_csv.extract_only_valid_subject()\n",
    "subjects"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "columns_multi = ['subject','fold', 'train accuracy', 'test accuracy']\n",
    "reg_multi = pd.DataFrame(columns = columns_multi)\n",
    "index = 1\n",
    "\n",
    "for sub in subjects:\n",
    "\n",
    "    string_sub = extract_correct_csv.read_correct_subject_csv(sub)\n",
    "\n",
    "    df_ = pd.read_csv('data/LookAtMe_0'+string_sub+'.csv', sep='\\t')\n",
    "    y = np.array(list([int (d > 2) for d in df_['rating']]))\n",
    "    y = y[48:]\n",
    "\n",
    "\n",
    "    X1 = pd.read_csv('data/features_4_2/hr/'+str(sub)+'.csv')\n",
    "    X1 = pd.DataFrame(scaler.fit_transform(X1))\n",
    "    X2 = pd.read_csv('data/features_4_2/eda/'+str(sub)+'.csv')\n",
    "    X2 = pd.DataFrame(scaler.fit_transform(X2))\n",
    "    X3 = pd.read_csv('data/features_4_2/pupil/'+str(sub)+'.csv')\n",
    "    X3 = pd.DataFrame(scaler.fit_transform(X3))\n",
    "    X = pd.concat([X1, X2, X3], axis=1)\n",
    "    X = X[48:]\n",
    "\n",
    "    X = pd.DataFrame(X)\n",
    "    X = X.reset_index().drop(columns=('index'))\n",
    "\n",
    "    sss = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=123)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(sss.split(X, y)):\n",
    "        y = pd.DataFrame(y)\n",
    "        y = y.reset_index().drop(columns=('index'))\n",
    "\n",
    "        N_train = len(train_index)\n",
    "        X_train = X.iloc[train_index, :]\n",
    "        y_train =y.iloc[train_index, :]\n",
    "\n",
    "        X_test = X.iloc[test_index, :]\n",
    "        y_test =y.iloc[test_index, :]\n",
    "\n",
    "        classifier = LogisticRegression(max_iter=10000,random_state=123)\n",
    "        clf.fit(X_train, np.squeeze(np.array(y_train)))\n",
    "\n",
    "        train_ = clf.score(X_train, y_train)\n",
    "        test_ = clf.score(X_test, y_test)\n",
    "        dict_ = {'subject': sub, 'fold':int(i), 'train accuracy': train_, 'test accuracy': test_}\n",
    "        reg_multi = pd.concat([reg_multi, pd.DataFrame(data=dict_, index=np.arange(1))], ignore_index=True)\n",
    "        index = index + 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## accuracy logistic classifier sklearn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reg_multi"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "columns = ['subject', 'fold']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## accuracy logistic classifier sklearn mean by subj"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped_df = reg_multi.groupby(by=['subject'], as_index=False).mean()\n",
    "grouped_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## mean accuracy over all subjs logistic classifier sklearn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped_df.drop(columns=['subject']).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## var over all subjs logistic classifier sklearn"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped_df.drop(columns=['subject']).var()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"test accuracy all physio\\nmean: \",np.mean(np.array(mean_test)))\n",
    "print('var: ',np.var(np.array(mean_test)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## sklearn logistic regression OU roi features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "columns_multi = ['subject','fold', 'train accuracy', 'test accuracy']\n",
    "reg_multi = pd.DataFrame(columns = columns_multi)\n",
    "index = 1\n",
    "\n",
    "df_ = pd.read_csv('data/gaze/joined_fixation.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'['"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_['Fixation feature'][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for sub in subjects:\n",
    "\n",
    "    string_sub = extract_correct_csv.read_correct_subject_csv(sub)\n",
    "\n",
    "\n",
    "    y = np.array(list([int (d > 2) for d in df_['rating']]))\n",
    "    y = y[48:]\n",
    "\n",
    "\n",
    "    X1 = pd.read_csv('data/features_4_2/hr/'+str(sub)+'.csv')\n",
    "    X1 = pd.DataFrame(scaler.fit_transform(X1))\n",
    "    X2 = pd.read_csv('data/features_4_2/eda/'+str(sub)+'.csv')\n",
    "    X2 = pd.DataFrame(scaler.fit_transform(X2))\n",
    "    X3 = pd.read_csv('data/features_4_2/pupil/'+str(sub)+'.csv')\n",
    "    X3 = pd.DataFrame(scaler.fit_transform(X3))\n",
    "    X = pd.concat([X1, X2, X3], axis=1)\n",
    "    X = X[48:]\n",
    "\n",
    "    X = pd.DataFrame(X)\n",
    "    X = X.reset_index().drop(columns=('index'))\n",
    "\n",
    "    sss = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=123)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(sss.split(X, y)):\n",
    "        y = pd.DataFrame(y)\n",
    "        y = y.reset_index().drop(columns=('index'))\n",
    "\n",
    "        N_train = len(train_index)\n",
    "        X_train = X.iloc[train_index, :]\n",
    "        y_train =y.iloc[train_index, :]\n",
    "\n",
    "        X_test = X.iloc[test_index, :]\n",
    "        y_test =y.iloc[test_index, :]\n",
    "\n",
    "        classifier = LogisticRegression(max_iter=10000,random_state=123)\n",
    "        clf.fit(X_train, np.squeeze(np.array(y_train)))\n",
    "\n",
    "        train_ = clf.score(X_train, y_train)\n",
    "        test_ = clf.score(X_test, y_test)\n",
    "        dict_ = {'subject': sub, 'fold':int(i), 'train accuracy': train_, 'test accuracy': test_}\n",
    "        reg_multi = pd.concat([reg_multi, pd.DataFrame(data=dict_, index=np.arange(1))], ignore_index=True)\n",
    "        index = index + 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MLP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "valid_subject = extract_correct_csv.extract_only_valid_subject()\n",
    "valid_subject.remove(50)\n",
    "valid_subject.remove(51)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# MLP mono signals\n",
    "columns_mono = ['Subject', 'Feature', 'Train', 'Test']\n",
    "MLP_df_mono = pd.DataFrame(columns=columns_mono)\n",
    "types_ = ['hr', 'eda', 'pupil']\n",
    "for sub in valid_subject:\n",
    "    string_sub = extract_correct_csv.read_correct_subject_csv(sub)\n",
    "    df_ = pd.read_csv('data/LookAtMe_0'+string_sub+'.csv', sep='\\t')\n",
    "    y = np.array(list([int (d > 2) for d in df_['rating']]))\n",
    "    y = y[48:]\n",
    "\n",
    "    for type_ in types_:\n",
    "        X = pd.read_csv('data/features_4_2/'+type_+'/'+str(sub)+'.csv')\n",
    "        X = pd.DataFrame(scaler.fit_transform(X))\n",
    "        X = X[48:]\n",
    "        X_train, X_test,y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123, stratify=y)\n",
    "        clf = MLPClassifier(hidden_layer_sizes=(30, 20), max_iter=3000, learning_rate='adaptive', random_state=123).fit(X_train, y_train)\n",
    "        row_ = {'Subject': sub,\n",
    "                'Feature': type_,\n",
    "                'Train': clf.score(X_train, y_train),\n",
    "                'Test':clf.score(X_test, y_test)}\n",
    "        MLP_df_mono = pd.concat([MLP_df_mono, pd.DataFrame(data=row_, index=np.arange(1))], ignore_index=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_mono = MLP_df_mono.groupby(by='Feature', as_index=False).mean()\n",
    "std_mono = MLP_df_mono.groupby(by='Feature', as_index=False).std()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# test tuning MLP\n",
    "first_layer_neurons = np.arange(10, 150, 10)\n",
    "second_layer_neurons = np.arange(10, 150, 10)\n",
    "third_layer_neurons = np.arange(10, 150, 10)\n",
    "\n",
    "\n",
    "best_hyperP = pd.DataFrame(columns=['first layer', 'second layer', 'third layer', 'train', 'test'])\n",
    "\n",
    "for first in first_layer_neurons:\n",
    "    for second in second_layer_neurons:\n",
    "        for third in third_layer_neurons:\n",
    "            mean_test = []\n",
    "            mean_train = []\n",
    "            for sub in valid_subject:\n",
    "                string_sub = extract_correct_csv.read_correct_subject_csv(sub)\n",
    "                df_ = pd.read_csv('data/LookAtMe_0'+string_sub+'.csv', sep='\\t')\n",
    "                y = np.array(list([int (d > 2) for d in df_['rating']]))\n",
    "                y = y[48:]\n",
    "                X1 = pd.read_csv('data/features_4_2/hr/'+str(sub)+'.csv')\n",
    "                X1 = pd.DataFrame(scaler.fit_transform(X1))\n",
    "                X2 = pd.read_csv('data/features_4_2/eda/'+str(sub)+'.csv')\n",
    "                X2 = pd.DataFrame(scaler.fit_transform(X2))\n",
    "                X3 = pd.read_csv('data/features_4_2/pupil/'+str(sub)+'.csv')\n",
    "                X3 = pd.DataFrame(scaler.fit_transform(X3))\n",
    "                X = pd.concat([X1, X2, X3], axis=1)\n",
    "                X = X[48:]\n",
    "                X_train, X_test,y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=123, stratify=y)\n",
    "                clf = MLPClassifier(hidden_layer_sizes=(first, second, third),\n",
    "                                    max_iter=3000,\n",
    "                                    learning_rate='adaptive',\n",
    "                                    random_state=123)\\\n",
    "                    .fit(X_train, y_train)\n",
    "                mean_train.append(clf.score(X_train, y_train))\n",
    "                mean_test.append(clf.score(X_test, y_test))\n",
    "\n",
    "            row_dict = {'first layer': first,\n",
    "                        'second layer': second,\n",
    "                        'third layer': third,\n",
    "                        'train': np.array(mean_train).mean(),\n",
    "                        'test': np.array(mean_test).mean()}\n",
    "            best_hyperP = pd.concat([best_hyperP, pd.DataFrame(data=row_dict, index=np.arange(1))], ignore_index=True)\n",
    "best_hyperP.to_csv('output_mlp.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_hyperP.loc[best_hyperP.test.idxmax()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "columns = ['Subject', 'Train', 'Test']\n",
    "\n",
    "mean_MLP_df = pd.DataFrame(columns=columns)\n",
    "for sub in valid_subject:\n",
    "    string_sub = extract_correct_csv.read_correct_subject_csv(sub)\n",
    "    df_ = pd.read_csv('data/LookAtMe_0'+string_sub+'.csv', sep='\\t')\n",
    "    y = np.array(list([int (d > 2) for d in df_['rating']]))\n",
    "    y = y[48:]\n",
    "\n",
    "\n",
    "    X1 = pd.read_csv('data/features_4_2/hr/'+str(sub)+'.csv')\n",
    "    X1 = pd.DataFrame(scaler.fit_transform(X1))\n",
    "    X2 = pd.read_csv('data/features_4_2/eda/'+str(sub)+'.csv')\n",
    "    X2 = pd.DataFrame(scaler.fit_transform(X2))\n",
    "    X3 = pd.read_csv('data/features_4_2/pupil/'+str(sub)+'.csv')\n",
    "    X3 = pd.DataFrame(scaler.fit_transform(X3))\n",
    "\n",
    "    X = pd.concat([X1, X2, X3], axis=1)\n",
    "    X = X[48:]\n",
    "    X_train, X_test,y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=123, stratify=y)\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(100, 50, 20), max_iter=1500, learning_rate='adaptive', random_state=123).fit(X_train, y_train)\n",
    "    row_ = {'Subject': sub,\n",
    "            'Train': clf.score(X_train, y_train),\n",
    "            'Test':clf.score(X_test, y_test)}\n",
    "    mean_MLP_df = pd.concat([mean_MLP_df, pd.DataFrame(data=row_, index=np.arange(1))], ignore_index=True)\n",
    "mean_MLP_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_MLP_df.Test.mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic regression with morph level"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# extract morph level functions\n",
    "def extract_cs(df):\n",
    "    cs1, cs2 = int(df[df.shock == True].picName.unique()[0][5]), int(df[df.shock == True].picName.unique()[1][5])\n",
    "    return cs1, cs2\n",
    "\n",
    "\n",
    "morph_pos = 11\n",
    "morph_value = 15\n",
    "\n",
    "\n",
    "def extract_threat_level(df):\n",
    "    MORPH_POS = 11\n",
    "    MORPH_VALUE = 15\n",
    "    threat_person = []\n",
    "    cs1_pic, cs2_pic = extract_cs(df)\n",
    "\n",
    "    for i in df.iterrows():\n",
    "        nome = i[1].picName\n",
    "        try:\n",
    "            if nome[5] == str(cs1_pic) or nome[5] == str(cs2_pic):\n",
    "                threat_person.append(6)\n",
    "                continue\n",
    "            elif int(nome[5]):\n",
    "                threat_person.append(1)\n",
    "                continue\n",
    "        except:\n",
    "            if (int(nome[MORPH_POS]) == cs1_pic) or (int(nome[MORPH_POS]) == cs2_pic):\n",
    "                if nome[MORPH_VALUE] == '2':\n",
    "                    threat_person.append(5)\n",
    "\n",
    "                elif nome[MORPH_VALUE] == '4':\n",
    "                    threat_person.append(4)\n",
    "\n",
    "                elif nome[MORPH_VALUE] == '6':\n",
    "                    threat_person.append(3)\n",
    "\n",
    "                elif nome[MORPH_VALUE] == '8':\n",
    "                    threat_person.append(2)\n",
    "                    continue\n",
    "            else:\n",
    "                if nome[MORPH_VALUE] == '2':\n",
    "                    threat_person.append(2)\n",
    "\n",
    "                elif nome[MORPH_VALUE] == '4':\n",
    "                    threat_person.append(3)\n",
    "\n",
    "                elif nome[MORPH_VALUE] == '6':\n",
    "                    threat_person.append(4)\n",
    "\n",
    "                elif nome[MORPH_VALUE] == '8':\n",
    "                    threat_person.append(5)\n",
    "    return threat_person"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "subjects = extract_correct_csv.extract_only_valid_subject()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 24)\n",
      "(112, 24)\n",
      "(112, 28)\n",
      "(112, 6)\n",
      "(160, 82)\n"
     ]
    }
   ],
   "source": [
    "columns = ['subject', 'feature', 'fold', 'train accuracy', 'test accuracy']\n",
    "results = pd.DataFrame(columns = columns)\n",
    "\n",
    "for x in subjects:\n",
    "    string_sub = extract_correct_csv.read_correct_subject_csv(x)\n",
    "    df_ = pd.read_csv('data/LookAtMe_0'+string_sub+'.csv', sep='\\t')\n",
    "    df_ = df_[48:]\n",
    "    y = np.array(list([int (d > 2) for d in df_['rating']]))\n",
    "\n",
    "\n",
    "    X1 = pd.read_csv('data/features_4_2/hr/'+str(x)+'.csv')\n",
    "    X1 = pd.DataFrame(scaler.fit_transform(X1))\n",
    "    X1 = X1[48:]\n",
    "    print(X1.shape)\n",
    "    X2 = pd.read_csv('data/features_4_2/eda/'+str(x)+'.csv')\n",
    "    X2 = pd.DataFrame(scaler.fit_transform(X2))\n",
    "    X2 = X2[48:]\n",
    "    print(X2.shape)\n",
    "    X3 = pd.read_csv('data/features_4_2/pupil/'+str(x)+'.csv')\n",
    "    X3 = pd.DataFrame(scaler.fit_transform(X3))\n",
    "    X3 = X3[48:]\n",
    "    print(X3.shape)\n",
    "    img = np.array(extract_threat_level(df_))\n",
    "    morph_level = np.zeros((img.size, img.max()))\n",
    "    morph_level[np.arange(img.size), img-1] = 1\n",
    "    X4 = morph_level.astype(int)\n",
    "    X4 = pd.DataFrame(X4)\n",
    "    print(X4)\n",
    "    X = pd.concat([X1, X2, X3, X4], axis=1)\n",
    "\n",
    "    #print(X.shape)\n",
    "    break\n",
    "    sss = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=123)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(sss.split(X, y)):\n",
    "        y = pd.DataFrame(y)\n",
    "        y = y.reset_index().drop(columns=('index'))\n",
    "\n",
    "        N_train = len(train_index)\n",
    "        X_train = X.iloc[train_index, :]\n",
    "        y_train =y.iloc[train_index, :]\n",
    "\n",
    "        X_test = X.iloc[test_index, :]\n",
    "        y_test =y.iloc[test_index, :]\n",
    "\n",
    "        clf = LogisticRegression(random_state=123,max_iter=10000)\n",
    "        clf.fit(X_train, np.squeeze(np.array(y_train)))\n",
    "\n",
    "        train_ = clf.score(X_train, y_train)\n",
    "        test_ = clf.score(X_test, y_test)\n",
    "        dict_ = {'subject': x, 'feature': 'morph level' ,'fold':int(i), 'train accuracy': train_, 'test accuracy': test_}\n",
    "        results = pd.concat([results, pd.DataFrame(data=dict_, index=np.arange(1))], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "         train accuracy  test accuracy\nsubject                               \n2              0.794007       0.811594\n4              0.670412       0.666667\n10             0.696629       0.782609\n41             0.771536       0.623188\n43             0.868914       0.855072\n44             0.707865       0.579710\n45             0.921348       0.913043\n46             0.655431       0.637681\n47             0.910112       0.840580\n48             0.734082       0.681159\n49             0.883895       0.884058\n50             0.677903       0.565217\n51             0.820225       0.869565\n52             0.760300       0.797101\n53             0.876404       0.869565\n54             0.891386       0.855072\n55             0.913858       0.942029",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train accuracy</th>\n      <th>test accuracy</th>\n    </tr>\n    <tr>\n      <th>subject</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>0.794007</td>\n      <td>0.811594</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.670412</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.696629</td>\n      <td>0.782609</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>0.771536</td>\n      <td>0.623188</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>0.868914</td>\n      <td>0.855072</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>0.707865</td>\n      <td>0.579710</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>0.921348</td>\n      <td>0.913043</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>0.655431</td>\n      <td>0.637681</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>0.910112</td>\n      <td>0.840580</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>0.734082</td>\n      <td>0.681159</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>0.883895</td>\n      <td>0.884058</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>0.677903</td>\n      <td>0.565217</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>0.820225</td>\n      <td>0.869565</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>0.760300</td>\n      <td>0.797101</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>0.876404</td>\n      <td>0.869565</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>0.891386</td>\n      <td>0.855072</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>0.913858</td>\n      <td>0.942029</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.groupby(by='subject').mean(numeric_only=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mean over all subjects"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "train accuracy    0.797312\ntest accuracy     0.774936\ndtype: float64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.drop(columns=['subject', 'fold']).mean(numeric_only=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "train accuracy    0.008994\ntest accuracy     0.019713\ndtype: float64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.drop(columns=['subject', 'fold']).var(numeric_only=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic regression with all signals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "columns = ['subject', 'feature', 'fold', 'train accuracy', 'test accuracy']\n",
    "results = pd.DataFrame(columns = columns)\n",
    "\n",
    "for x in subjects:\n",
    "    string_sub = extract_correct_csv.read_correct_subject_csv(x)\n",
    "    df_ = pd.read_csv('data/LookAtMe_0'+string_sub+'.csv', sep='\\t')\n",
    "    df_ = df_[48:]\n",
    "    y = np.array(list([int (d > 2) for d in df_['rating']]))\n",
    "\n",
    "\n",
    "    img = np.array(extract_threat_level(df_))\n",
    "    morph_level = np.zeros((img.size, img.max()))\n",
    "    morph_level[np.arange(img.size), img-1] = 1\n",
    "    X = morph_level.astype(int)\n",
    "    X = pd.DataFrame(X)\n",
    "    X = X.reset_index().drop(columns='index')\n",
    "\n",
    "    sss = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=123)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(sss.split(X, y)):\n",
    "        y = pd.DataFrame(y)\n",
    "        y = y.reset_index().drop(columns=('index'))\n",
    "\n",
    "        N_train = len(train_index)\n",
    "        X_train = X.iloc[train_index, :]\n",
    "        y_train =y.iloc[train_index, :]\n",
    "\n",
    "        X_test = X.iloc[test_index, :]\n",
    "        y_test =y.iloc[test_index, :]\n",
    "\n",
    "        clf = LogisticRegression(random_state=123,max_iter=10000)\n",
    "        clf.fit(X_train, np.squeeze(np.array(y_train)))\n",
    "\n",
    "        train_ = clf.score(X_train, y_train)\n",
    "        test_ = clf.score(X_test, y_test)\n",
    "        dict_ = {'subject': x, 'feature': 'morph level' ,'fold':int(i), 'train accuracy': train_, 'test accuracy': test_}\n",
    "        results = pd.concat([results, pd.DataFrame(data=dict_, index=np.arange(1))], ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results with our model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "     subject  k  fold     train      test\n0          2  2     0  0.505618  0.478261\n1          2  2     1  0.617978  0.739130\n2          2  2     2  0.494382  0.521739\n3          2  3     0  0.213483  0.391304\n4          2  3     1  0.786517  0.869565\n..       ... ..   ...       ...       ...\n235       55  5     1  0.674157  0.652174\n236       55  5     2  0.573034  0.521739\n237       55  6     0  0.292135  0.304348\n238       55  6     1  0.550562  0.521739\n239       55  6     2  0.292135  0.478261\n\n[240 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>subject</th>\n      <th>k</th>\n      <th>fold</th>\n      <th>train</th>\n      <th>test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.505618</td>\n      <td>0.478261</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0.617978</td>\n      <td>0.739130</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0.494382</td>\n      <td>0.521739</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0.213483</td>\n      <td>0.391304</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.786517</td>\n      <td>0.869565</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>235</th>\n      <td>55</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0.674157</td>\n      <td>0.652174</td>\n    </tr>\n    <tr>\n      <th>236</th>\n      <td>55</td>\n      <td>5</td>\n      <td>2</td>\n      <td>0.573034</td>\n      <td>0.521739</td>\n    </tr>\n    <tr>\n      <th>237</th>\n      <td>55</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0.292135</td>\n      <td>0.304348</td>\n    </tr>\n    <tr>\n      <th>238</th>\n      <td>55</td>\n      <td>6</td>\n      <td>1</td>\n      <td>0.550562</td>\n      <td>0.521739</td>\n    </tr>\n    <tr>\n      <th>239</th>\n      <td>55</td>\n      <td>6</td>\n      <td>2</td>\n      <td>0.292135</td>\n      <td>0.478261</td>\n    </tr>\n  </tbody>\n</table>\n<p>240 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mono_im = pd.read_csv('output/FA/FA_only_image.csv')\n",
    "mono_im"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "complete_image = pd.read_csv('output/FA/FA_kcv_norm_image_new.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
