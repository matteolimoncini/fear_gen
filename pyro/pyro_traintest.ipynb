{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import\n",
    "import os\n",
    "from functools import partial\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import warnings\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "from pyro.infer import MCMC, NUTS\n",
    "\n",
    "# for CI testing\n",
    "warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)\n",
    "smoke_test = ('CI' in os.environ)\n",
    "assert pyro.__version__.startswith('1.8.4')\n",
    "pyro.set_rng_seed(1)\n",
    "\n",
    "\n",
    "# Set matplotlib settings\n",
    "%matplotlib inline\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Extract morphing level and shock (binary morphing level)\n",
    "\n",
    "# Equal for all subjects\n",
    "df = pd.read_csv('../data/newLookAtMe/newLookAtMe20.csv')\n",
    "data = df[['morphing level', 'shock']]\n",
    "data['shock'] = data['shock'].astype(int)\n",
    "data['morphing level'] = [int(d==6) for d in data['morphing level']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create tensor where:\n",
    "* `[0 0] = 0`\n",
    "* `[1 0] = 1`\n",
    "* `[1 1] = 2`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([160, 2])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model = data.to_numpy()\n",
    "data_final = []\n",
    "for x in data_model:\n",
    "    if (x == [0, 0]).all():\n",
    "        data_final.append(0)\n",
    "    elif (x == [1, 0]).all():\n",
    "        data_final.append(1)\n",
    "    else:\n",
    "        data_final.append(2)\n",
    "\n",
    "data_final = torch.tensor(data_final)\n",
    "data_model_tensor = torch.tensor(data_model)\n",
    "data_model_tensor.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "$p(data\\, final | \\theta) = \\prod_i^3\\theta_k^{N_k}$\n",
    "\n",
    "where $\\theta$ is a vector 3-dimensional modeled with a Dirichlet Distribution"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0, 0],\n       [1, 0],\n       [1, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [1, 0],\n       [1, 0],\n       [0, 0],\n       [1, 0],\n       [1, 0],\n       [0, 0],\n       [1, 0],\n       [0, 0],\n       [1, 0],\n       [0, 0],\n       [1, 1],\n       [0, 0],\n       [0, 0],\n       [1, 1],\n       [0, 0],\n       [1, 1],\n       [1, 1],\n       [0, 0],\n       [1, 0],\n       [1, 1],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [1, 1],\n       [1, 0],\n       [0, 0],\n       [1, 1],\n       [1, 1],\n       [0, 0],\n       [1, 0],\n       [0, 0],\n       [1, 1],\n       [0, 0],\n       [1, 0],\n       [0, 0],\n       [1, 1],\n       [0, 0],\n       [1, 1],\n       [0, 0],\n       [1, 1],\n       [0, 0],\n       [0, 0],\n       [1, 1],\n       [0, 0],\n       [0, 0],\n       [1, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [1, 1],\n       [0, 0],\n       [0, 0],\n       [1, 0],\n       [0, 0],\n       [1, 0],\n       [0, 0],\n       [0, 0],\n       [1, 1],\n       [0, 0],\n       [1, 1],\n       [0, 0],\n       [0, 0],\n       [1, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [1, 1],\n       [0, 0],\n       [0, 0],\n       [1, 0],\n       [0, 0],\n       [0, 0],\n       [1, 1],\n       [1, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [1, 0],\n       [0, 0],\n       [0, 0],\n       [1, 1],\n       [0, 0],\n       [0, 0],\n       [1, 0],\n       [0, 0],\n       [1, 1],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [1, 0],\n       [0, 0],\n       [1, 1],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [1, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [1, 1],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [1, 0],\n       [0, 0],\n       [1, 1],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [1, 1],\n       [1, 0],\n       [0, 0],\n       [0, 0],\n       [1, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [1, 0],\n       [1, 1],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [1, 1],\n       [0, 0],\n       [0, 0],\n       [1, 1],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [1, 1],\n       [0, 0],\n       [0, 0],\n       [1, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [0, 0],\n       [1, 0]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# model definition\n",
    "\n",
    "# uniform prior\n",
    "prior_counts = torch.ones((2,2))\n",
    "\n",
    "def simple_model(data):\n",
    "    theta = pyro.sample(\"theta\", dist.Dirichlet(prior_counts))\n",
    "    total_counts = int(data.sum())\n",
    "    pyro.sample(\"likelihood\", dist.Multinomial(total_counts, theta), obs=data)\n",
    "\n",
    "counter = torch.tensor(np.unique(data_model, axis=0, return_counts=True)[1])\n",
    "counter_prova = torch.tensor([[28, 0], [5,15]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1200/1200 [00:08, 138.08it/s, step size=7.24e-01, acc. prob=0.908]\n"
     ]
    }
   ],
   "source": [
    "nuts_kernel = NUTS(simple_model)\n",
    "num_samples, warmup_steps = (1000, 200) if not smoke_test else (10, 10)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=1000, warmup_steps=200)\n",
    "mcmc.run(counter_prova)\n",
    "hmc_samples = {k: v.detach().cpu().numpy()\n",
    "               for k, v in mcmc.get_samples().items()}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "not_agg_data = data_model_tensor[data_model_tensor[:,0] == 0]\n",
    "agg_data = data_model_tensor[data_model_tensor[:,0] == 1]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([160, 2])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_model_tensor.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([28, 28])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(agg_data, return_counts=True, axis=0)[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "prior_aggressive = torch.ones(2)\n",
    "prior_not_aggressive = torch.ones(2)\n",
    "\n",
    "def model(data):\n",
    "    not_agg_data = data[data[:,0] == 0]\n",
    "    agg_data = data[data[:,0] == 1]\n",
    "\n",
    "    count_values_1 = torch.tensor(np.append(np.unique(not_agg_data, return_counts=True, axis=0)[1], 0))\n",
    "    count_values_2 = torch.tensor(np.unique(agg_data, return_counts=True, axis=0)[1])\n",
    "\n",
    "    theta1 = pyro.sample(\"theta1\", dist.Dirichlet(prior_aggressive))\n",
    "    theta2 = pyro.sample(\"theta2\", dist.Dirichlet(prior_not_aggressive))\n",
    "\n",
    "    counts1 = int(count_values_1.sum())\n",
    "    counts2 = int(count_values_2.sum())\n",
    "\n",
    "    pyro.sample(\"likelihood1\", dist.Multinomial(counts1, theta1), obs = count_values_1)\n",
    "    pyro.sample(\"likelihood2\", dist.Multinomial(counts2, theta2), obs = count_values_2)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample: 100%|██████████| 1200/1200 [00:14, 83.37it/s, step size=9.04e-01, acc. prob=0.912] \n"
     ]
    }
   ],
   "source": [
    "nuts_kernel = NUTS(model)\n",
    "num_samples, warmup_steps = (1000, 200) if not smoke_test else (10, 10)\n",
    "mcmc = MCMC(nuts_kernel, num_samples=1000, warmup_steps=200)\n",
    "mcmc.run(data_model_tensor[16:48])\n",
    "hmc_samples = {k: v.detach().cpu().numpy()\n",
    "               for k, v in mcmc.get_samples().items()}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9465429  0.05345723]\n",
      "[0.27769166 0.722309  ]\n"
     ]
    }
   ],
   "source": [
    "dist_cs_minus = hmc_samples['theta1'].mean(axis=0)\n",
    "dist_cs_plus = hmc_samples['theta2'].mean(axis=0)\n",
    "print(dist_cs_minus)\n",
    "print(dist_cs_plus)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "La cella sopra indica le probabilità di vedere una coppia `[0 0]`, una coppia `[1 0]` o una coppia `[1 1]`, ma non $P(shock | morph\\, level)$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n        0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test, y_test = data_model_tensor[48:,0], data_model_tensor[48:,1]\n",
    "y_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "(112,)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values = torch.unique(x_test, return_counts = True)[1]\n",
    "shock = unique_values[1]\n",
    "no_shock = unique_values[0]\n",
    "# predictive marcio\n",
    "prediction = torch.tensor([])\n",
    "for i in x_test:\n",
    "    if int(i) == 0:\n",
    "        prediction = torch.cat((prediction, dist.Bernoulli(torch.tensor([dist_cs_minus[1]])).sample()))\n",
    "    else:\n",
    "        prediction = torch.cat((prediction, dist.Bernoulli(torch.tensor([dist_cs_plus[1]])).sample()))\n",
    "    #dist.Bernoulli(torch.tensor([dio1[1]])).sample(sample_shape=(shock,1))\n",
    "\n",
    "prediction = np.array(prediction)\n",
    "prediction.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Results check"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "  Subject       ICC  Accuracy Score  Precision    Recall  F1 score\n0       1  0.007082        0.571429   0.379310  0.268293  0.314286\n0       2  0.302598        0.669643   0.827586  0.428571  0.564706\n0       4  0.106040        0.571429   0.689655  0.338983  0.454545\n0       5  0.326913        0.696429   0.724138  0.446809  0.552632\n0       6  0.432225        0.785714   0.551724  0.592593  0.571429\n0       7  0.304075        0.678571   0.758621  0.431373  0.550000\n0      13  0.030008        0.526786   0.689655  0.312500  0.430108\n0      15  0.370391        0.732143   0.655172  0.487179  0.558824\n0      16  0.153423        0.616071   0.586207  0.354167  0.441558\n0      17 -0.031969        0.491071   0.689655  0.294118  0.412371\n0      21 -0.031969        0.491071   0.689655  0.294118  0.412371\n0      22  0.438133        0.758929   0.724138  0.525000  0.608696\n0      23  0.234747        0.642857   0.724138  0.396226  0.512195\n0      26  0.359492        0.732143   0.620690  0.486486  0.545455\n0      27  0.690130        0.875000   0.827586  0.727273  0.774194\n0      28  0.479850        0.776786   0.758621  0.550000  0.637681\n0      31  0.619786        0.848214   0.758621  0.687500  0.721311\n0      32 -0.006761        0.508929   0.655172  0.296875  0.408602\n0      33  0.326913        0.696429   0.724138  0.446809  0.552632\n0      41  0.273812        0.696429   0.551724  0.432432  0.484848\n0      43  0.445989        0.750000   0.827586  0.510638  0.631579\n0      44  0.097414        0.553571   0.827586  0.347826  0.489796\n0      45  0.530655        0.803571   0.758621  0.594595  0.666667\n0      46 -0.052821        0.482143   0.655172  0.283582  0.395833\n0      47  0.478779        0.767857   0.827586  0.533333  0.648649\n0      48  0.128223        0.589286   0.655172  0.345455  0.452381\n0      50  0.176965        0.598214   0.827586  0.375000  0.516129\n0      51  0.348974        0.714286   0.689655  0.465116  0.555556\n0      52  0.229311        0.669643   0.551724  0.400000  0.463768\n0      54  0.471332        0.767857   0.793103  0.534884  0.638889",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Subject</th>\n      <th>ICC</th>\n      <th>Accuracy Score</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>F1 score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.007082</td>\n      <td>0.571429</td>\n      <td>0.379310</td>\n      <td>0.268293</td>\n      <td>0.314286</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>0.302598</td>\n      <td>0.669643</td>\n      <td>0.827586</td>\n      <td>0.428571</td>\n      <td>0.564706</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>4</td>\n      <td>0.106040</td>\n      <td>0.571429</td>\n      <td>0.689655</td>\n      <td>0.338983</td>\n      <td>0.454545</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>5</td>\n      <td>0.326913</td>\n      <td>0.696429</td>\n      <td>0.724138</td>\n      <td>0.446809</td>\n      <td>0.552632</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>0.432225</td>\n      <td>0.785714</td>\n      <td>0.551724</td>\n      <td>0.592593</td>\n      <td>0.571429</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>7</td>\n      <td>0.304075</td>\n      <td>0.678571</td>\n      <td>0.758621</td>\n      <td>0.431373</td>\n      <td>0.550000</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>13</td>\n      <td>0.030008</td>\n      <td>0.526786</td>\n      <td>0.689655</td>\n      <td>0.312500</td>\n      <td>0.430108</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>15</td>\n      <td>0.370391</td>\n      <td>0.732143</td>\n      <td>0.655172</td>\n      <td>0.487179</td>\n      <td>0.558824</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>16</td>\n      <td>0.153423</td>\n      <td>0.616071</td>\n      <td>0.586207</td>\n      <td>0.354167</td>\n      <td>0.441558</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>17</td>\n      <td>-0.031969</td>\n      <td>0.491071</td>\n      <td>0.689655</td>\n      <td>0.294118</td>\n      <td>0.412371</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>21</td>\n      <td>-0.031969</td>\n      <td>0.491071</td>\n      <td>0.689655</td>\n      <td>0.294118</td>\n      <td>0.412371</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>22</td>\n      <td>0.438133</td>\n      <td>0.758929</td>\n      <td>0.724138</td>\n      <td>0.525000</td>\n      <td>0.608696</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>23</td>\n      <td>0.234747</td>\n      <td>0.642857</td>\n      <td>0.724138</td>\n      <td>0.396226</td>\n      <td>0.512195</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>26</td>\n      <td>0.359492</td>\n      <td>0.732143</td>\n      <td>0.620690</td>\n      <td>0.486486</td>\n      <td>0.545455</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>27</td>\n      <td>0.690130</td>\n      <td>0.875000</td>\n      <td>0.827586</td>\n      <td>0.727273</td>\n      <td>0.774194</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>28</td>\n      <td>0.479850</td>\n      <td>0.776786</td>\n      <td>0.758621</td>\n      <td>0.550000</td>\n      <td>0.637681</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>31</td>\n      <td>0.619786</td>\n      <td>0.848214</td>\n      <td>0.758621</td>\n      <td>0.687500</td>\n      <td>0.721311</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>32</td>\n      <td>-0.006761</td>\n      <td>0.508929</td>\n      <td>0.655172</td>\n      <td>0.296875</td>\n      <td>0.408602</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>33</td>\n      <td>0.326913</td>\n      <td>0.696429</td>\n      <td>0.724138</td>\n      <td>0.446809</td>\n      <td>0.552632</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>41</td>\n      <td>0.273812</td>\n      <td>0.696429</td>\n      <td>0.551724</td>\n      <td>0.432432</td>\n      <td>0.484848</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>43</td>\n      <td>0.445989</td>\n      <td>0.750000</td>\n      <td>0.827586</td>\n      <td>0.510638</td>\n      <td>0.631579</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>44</td>\n      <td>0.097414</td>\n      <td>0.553571</td>\n      <td>0.827586</td>\n      <td>0.347826</td>\n      <td>0.489796</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>45</td>\n      <td>0.530655</td>\n      <td>0.803571</td>\n      <td>0.758621</td>\n      <td>0.594595</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>46</td>\n      <td>-0.052821</td>\n      <td>0.482143</td>\n      <td>0.655172</td>\n      <td>0.283582</td>\n      <td>0.395833</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>47</td>\n      <td>0.478779</td>\n      <td>0.767857</td>\n      <td>0.827586</td>\n      <td>0.533333</td>\n      <td>0.648649</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>48</td>\n      <td>0.128223</td>\n      <td>0.589286</td>\n      <td>0.655172</td>\n      <td>0.345455</td>\n      <td>0.452381</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>50</td>\n      <td>0.176965</td>\n      <td>0.598214</td>\n      <td>0.827586</td>\n      <td>0.375000</td>\n      <td>0.516129</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>51</td>\n      <td>0.348974</td>\n      <td>0.714286</td>\n      <td>0.689655</td>\n      <td>0.465116</td>\n      <td>0.555556</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>52</td>\n      <td>0.229311</td>\n      <td>0.669643</td>\n      <td>0.551724</td>\n      <td>0.400000</td>\n      <td>0.463768</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>54</td>\n      <td>0.471332</td>\n      <td>0.767857</td>\n      <td>0.793103</td>\n      <td>0.534884</td>\n      <td>0.638889</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from pyirr import intraclass_correlation\n",
    "from fear_gen.extract_correct_csv import extract_only_valid_subject, read_correct_subject_csv\n",
    "\n",
    "\n",
    "correlation_df = pd.DataFrame(columns=['Subject', 'ICC', 'Accuracy Score', 'Precision', 'Recall', 'F1 score'])\n",
    "os.chdir('..')\n",
    "valid_subjects = extract_only_valid_subject()\n",
    "os.chdir('pyro')\n",
    "\n",
    "for i in valid_subjects:\n",
    "    subj_ = read_correct_subject_csv(i)\n",
    "    df_sub = pd.read_csv('../data/newLookAtMe/newLookAtMe'+subj_+'.csv')\n",
    "    df_sub = df_sub[48:]\n",
    "    rating = [int(d > 2) for d in df_sub['rating']]\n",
    "    bad = ~np.logical_or(np.isnan(rating), np.isnan(prediction))\n",
    "    rating_sub = np.compress(bad, rating)\n",
    "    rating_rational = np.compress(bad, prediction)\n",
    "\n",
    "    icc_df = pd.DataFrame()\n",
    "    icc_df['Rating'] = rating_sub\n",
    "    icc_df['Prediction'] = rating_rational\n",
    "\n",
    "    icc = intraclass_correlation(icc_df).value\n",
    "    accuracy_ = accuracy_score(rating_sub, rating_rational)\n",
    "    precision_ = precision_score(rating_sub, rating_rational)\n",
    "    recall_ = recall_score(rating_sub, rating_rational)\n",
    "    f1_ = f1_score(rating_sub, rating_rational)\n",
    "\n",
    "    df_tmp = pd.DataFrame({'Subject':i,'ICC':icc,'Accuracy Score':accuracy_,'Precision':precision_,'Recall':recall_, 'F1 score':f1_},index=np.arange(1))\n",
    "    correlation_df = pd.concat([correlation_df,df_tmp])\n",
    "\n",
    "correlation_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
