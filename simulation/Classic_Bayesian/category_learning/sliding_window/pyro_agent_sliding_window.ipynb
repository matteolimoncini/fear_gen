{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## import"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import pyro\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO, MCMC, NUTS\n",
    "import pyro.distributions as dist\n",
    "import pyro.distributions.constraints as constraints\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\",category=FutureWarning)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from autorank import autorank, plot_stats, create_report, latex_table\n",
    "from pyirr import intraclass_correlation\n",
    "\n",
    "pyro.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pwd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from fear_gen import extract_correct_csv\n",
    "os.chdir('../../../')\n",
    "valid_sub = extract_correct_csv.extract_only_valid_subject()\n",
    "os.chdir('pyro/category_learning/sliding_window')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def anxious_subjects(path, n, type='top'):\n",
    "    '''\n",
    "\n",
    "    :param path: path sias score or linear deviation score\n",
    "    :param n: number of subjects\n",
    "    :param type: 'top' or 'bot'\n",
    "    :return: top or bot n subjects sorted by sias score\n",
    "    '''\n",
    "    valid_subjects = extract_correct_csv.extract_only_valid_subject()\n",
    "    df = pd.read_csv(path).dropna().reset_index(drop=True)\n",
    "    df = df[df.subject.isin(valid_subjects)]\n",
    "    df['subject'] = [int(x) for x in df['subject']]\n",
    "    if type=='top':\n",
    "        return df.sort_values(by=df.columns[1], ascending=False).subject[:n].values\n",
    "    else:\n",
    "        return df.sort_values(by=df.columns[1], ascending=False).subject[-n:].values\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def counter_window(data, k=0):\n",
    "    N = data.shape[0]\n",
    "    counter = torch.zeros((N,4))\n",
    "    for i in range(len(data)):\n",
    "        dict_ = {'[0 0]':0, '[0 1]': 0, '[1 0]':0, '[1 1]':0}\n",
    "        if k == 0 or k > i:\n",
    "            tmp_data = data[:i+1]\n",
    "        else:\n",
    "            tmp_data = data[i-k:i+1]\n",
    "            #print('im here')\n",
    "        # count occurencies\n",
    "        for x in tmp_data:\n",
    "            dict_[str(x)] += 1\n",
    "        values = np.array(list(dict_.values()))\n",
    "        counter[i] = torch.tensor(values)\n",
    "    return counter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('data/newLookAtMe/newLookAtMe02.csv')\n",
    "df_rational = df[['morphing level', 'shock']] #consider only morphing level and shock\n",
    "df_rational['shock'] = df_rational['shock'].astype(int) # setting shock as int instead of boolean\n",
    "df_rational['morphing level'] = [int(d==6) for d in df_rational['morphing level']] # if morphing level==6 -> 1\n",
    "df_rational = df_rational.to_numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "counter = counter_window(df_rational, 3)\n",
    "counter = counter.reshape((len(df_rational), 2, 2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# model sliding window"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# categorical/multinomial distribution\n",
    "\n",
    "# uniform prior\n",
    "prior_counts = torch.ones((2,2))\n",
    "\n",
    "\n",
    "#model\n",
    "def model(data):\n",
    "    prior = pyro.sample(\"prior\", dist.Dirichlet(prior_counts))\n",
    "    total_counts = int(data.sum())\n",
    "    pyro.sample(\"likelihood\", dist.Multinomial(total_counts, prior), obs=data)\n",
    "\n",
    "\n",
    "nuts_kernel = NUTS(model)\n",
    "num_samples, warmup_steps = (300, 200)\n",
    "\n",
    "mcmc = MCMC(nuts_kernel, num_samples=num_samples, warmup_steps=warmup_steps, disable_progbar=True)\n",
    "all_means = []\n",
    "\n",
    "# sampling\n",
    "for i in range(len(counter)):\n",
    "    mcmc.run(counter[i])\n",
    "    hmc_samples = {k: v.detach().cpu().numpy()\n",
    "                   for k, v in mcmc.get_samples().items()}\n",
    "    means = hmc_samples['prior'].mean(axis=0)\n",
    "    stds = hmc_samples['prior'].std(axis=0)\n",
    "    print('observation: ', df_rational[i])\n",
    "    print('probabilities: ', means)\n",
    "    all_means.append(means)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analysis sliding window K"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "k_wind = [2, 5, 10, 25, 50, 100, 150]\n",
    "HAB_TRIALS = 16\n",
    "os.chdir('../../../')\n",
    "path_sias = 'data/sias_score.csv'\n",
    "path_lds = 'data/lds_subjects.csv'\n",
    "\n",
    "len_sub = 6\n",
    "top_lds = anxious_subjects(path_lds, len_sub, 'top')\n",
    "bot_lds = anxious_subjects(path_lds, len_sub, 'bot')\n",
    "\n",
    "top_sias = anxious_subjects(path_sias, len_sub)\n",
    "bot_sias = anxious_subjects(path_sias, len_sub, 'bot')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_correlation = pd.DataFrame(columns=['subject','k','pearson','r2score','person_disc','cohen_disc','icc'])\n",
    "\n",
    "for k in list(k_wind):\n",
    "\n",
    "    # read output of the rational model with different K\n",
    "    array_csplus_simulated = np.load('output/pyro/sliding_wind/k'+str(k)+'_csplus.npy',allow_pickle=True)\n",
    "    array_csminus_simulated = np.load('output/pyro/sliding_wind/k'+str(k)+'_csminus.npy',allow_pickle=True)\n",
    "    total_array_simulated = np.load('output/pyro/sliding_wind/k'+str(k)+'_total.npy',allow_pickle=True)\n",
    "\n",
    "    rating_rational_subj = total_array_simulated[HAB_TRIALS:] #remove habituation trials\n",
    "\n",
    "\n",
    "    for sub in valid_sub:\n",
    "        subj_ = extract_correct_csv.read_correct_subject_csv(sub)\n",
    "\n",
    "        #read data of real subjects\n",
    "        df_sub = pd.read_csv('data/newLookAtMe/newLookAtMe'+subj_+'.csv')\n",
    "        df_sub = df_sub[['shock', 'rating', 'morphing level']]\n",
    "        df_sub['shock'] = df_sub['shock'].astype(int) #convert shock from boolean to int\n",
    "        df_sub['morphing level'] = [int(d == 6) for d in df_sub['morphing level']]\n",
    "        df_sub['rating'] = df_sub['rating'].replace([1, 2, 3, 4, 5], [0.2, 0.4, 0.6, 0.8, 1]) #convert vote into (0,1)\n",
    "        df_sub_learn = df_sub[HAB_TRIALS:] #remove habituation trials\n",
    "        rating_sub = np.array(df_sub_learn['rating'])\n",
    "\n",
    "        rating_rational = rating_rational_subj\n",
    "        #remove trial from rating agent simulation and real data if in one list is nan\n",
    "        bad = ~np.logical_or(np.isnan(rating_sub), np.isnan(rating_rational))\n",
    "        rating_sub = np.compress(bad, rating_sub)\n",
    "        rating_rational = np.compress(bad, rating_rational)\n",
    "\n",
    "        #discretization of rating rational\n",
    "        round_vector = np.array([0.2, 0.4, 0.6, 0.8, 1])\n",
    "        rating_rational_discr = np.round(rating_rational / 0.2) * 0.2\n",
    "        rating_rational_discr = np.clip(rating_rational_discr, round_vector.min(), round_vector.max())\n",
    "\n",
    "        # calculate pearson correlation coefficient between k-rational model and real data\n",
    "        pearson = round(np.corrcoef(rating_sub,rating_rational)[0][1],2)\n",
    "\n",
    "        # calculate r2 score between k-rational model and real data\n",
    "        r2 = round(r2_score(rating_sub,rating_rational),2)\n",
    "\n",
    "        # calculate pearson correlation coefficient between k-rational model and real data using discrete values for k-rational model\n",
    "        pearson_disc = round(np.corrcoef(rating_sub,rating_rational_discr)[0][1],2)\n",
    "\n",
    "        # calculate cohen kappa between k-rational model and real data using discrete values for k-rational model\n",
    "        cohen_disc = round(cohen_kappa_score(rating_sub*10,rating_rational_discr*10),2)\n",
    "\n",
    "        # intraclass_correlation\n",
    "        #df_sub_ = df_global[df_global.Subject == x].dropna().drop(columns=['Subject']).reset_index(drop=True)\n",
    "        df_icc = pd.DataFrame({'rating_sub': rating_sub, 'rating_rational_discr': rating_rational_discr})\n",
    "        icc = intraclass_correlation(df_icc).value\n",
    "\n",
    "        # write line\n",
    "        df_tmp = pd.DataFrame({'subject':sub,'k':k,'pearson':pearson,'r2score':r2,'person_disc':pearson_disc,'cohen_disc':cohen_disc,'icc':icc},index=np.arange(1))\n",
    "        df_correlation = pd.concat([df_correlation,df_tmp])\n",
    "\n",
    "df_correlation['subject'] = [float(x) for x in df_correlation['subject']] #convert subjects into float\n",
    "\n",
    "# read social anxiety values\n",
    "sias_df = pd.read_csv('data/sias_score.csv').drop(columns='social_anxiety')\n",
    "sias_df['subject'] = [float(x) for x in sias_df['subject']] #convert subjects into float\n",
    "\n",
    "# read linear deviation score (how much this subject do fear generalization)\n",
    "lds_df = pd.read_csv('data/lds_subjects.csv')\n",
    "lds_df['subject'] = [float(x) for x in lds_df['subject']] #convert subjects into float"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# one dataframe with social anxiety, linear devation score and correlation measures for each subject\n",
    "res = pd.merge(sias_df, lds_df)\n",
    "df_correlation = pd.merge(res,df_correlation).dropna().reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pwd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_correlation.to_csv('output/pyro/sliding_wind/correlation.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_sias = './data/sias_score.csv'\n",
    "path_lds = './data/lds_subjects.csv'\n",
    "len_sub = 6\n",
    "\n",
    "# extract the 6 most/least generalization subjects and the 6 most/least anxious subjects\n",
    "top_lds_list = anxious_subjects(path_lds, len_sub, 'top')\n",
    "bot_lds_list = anxious_subjects(path_lds, len_sub, 'bot')\n",
    "top_sias_list = anxious_subjects(path_sias, len_sub, 'top')\n",
    "bot_sias_list = anxious_subjects(path_sias, len_sub, 'bot')\n",
    "\n",
    "df_results = pd.DataFrame(columns=['k','lds/sias','high/low','pearson','r2score','person_disc','cohen_disc','icc'])\n",
    "for k in list(k_wind):\n",
    "    lds = df_correlation[df_correlation['k']==k]\n",
    "\n",
    "    pearson_sias_high = lds[lds.subject.isin(top_sias_list)]['pearson'].median()\n",
    "    pearson_sias_low = lds[lds.subject.isin(bot_sias_list)]['pearson'].median()\n",
    "\n",
    "    r2_sias_high = lds[lds.subject.isin(top_sias_list)]['r2score'].median()\n",
    "    r2_sias_low = lds[lds.subject.isin(bot_sias_list)]['r2score'].median()\n",
    "\n",
    "    discrete_pearson_sias_high = lds[lds.subject.isin(top_sias_list)]['person_disc'].median()\n",
    "    discrete_pearson_sias_low = lds[lds.subject.isin(bot_sias_list)]['person_disc'].median()\n",
    "\n",
    "    icc_sias_high = lds[lds.subject.isin(top_sias_list)]['icc'].median()\n",
    "    icc_sias_low = lds[lds.subject.isin(bot_sias_list)]['icc'].median()\n",
    "\n",
    "    cohen_sias_high = lds[lds.subject.isin(top_sias_list)]['cohen_disc'].median()\n",
    "    cohen_sias_low = lds[lds.subject.isin(bot_sias_list)]['cohen_disc'].median()\n",
    "    pearson_lds_high = lds[lds.subject.isin(top_lds_list)]['pearson'].median()\n",
    "    pearson_lds_low = lds[lds.subject.isin(bot_lds_list)]['pearson'].median()\n",
    "\n",
    "    r2_lds_high = lds[lds.subject.isin(top_lds_list)]['r2score'].median()\n",
    "    r2_lds_low = lds[lds.subject.isin(bot_lds_list)]['r2score'].median()\n",
    "\n",
    "    discrete_pearson_lds_high = lds[lds.subject.isin(top_lds_list)]['person_disc'].median()\n",
    "    discrete_pearson_lds_low = lds[lds.subject.isin(bot_lds_list)]['person_disc'].median()\n",
    "\n",
    "    icc_lds_high = lds[lds.subject.isin(top_lds_list)]['icc'].median()\n",
    "    icc_lds_low = lds[lds.subject.isin(bot_lds_list)]['icc'].median()\n",
    "\n",
    "    cohen_lds_high = lds[lds.subject.isin(top_lds_list)]['cohen_disc'].median()\n",
    "    cohen_lds_low = lds[lds.subject.isin(bot_lds_list)]['cohen_disc'].median()\n",
    "\n",
    "    # write line\n",
    "    df_tmp = pd.DataFrame({'k':k,'lds/sias':'lds','high/low':'high','pearson':pearson_lds_high,'r2score':r2_lds_high,'person_disc':discrete_pearson_lds_high,'cohen_disc':cohen_lds_high,'icc':icc_lds_high},index=np.arange(1))\n",
    "    df_results = pd.concat([df_results,df_tmp])\n",
    "\n",
    "    df_tmp = pd.DataFrame({'k':k,'lds/sias':'lds','high/low':'low','pearson':pearson_lds_low,'r2score':r2_lds_low,'person_disc':discrete_pearson_lds_low,'cohen_disc':cohen_lds_low,'icc':icc_lds_low},index=np.arange(1))\n",
    "    df_results = pd.concat([df_results,df_tmp])\n",
    "\n",
    "    df_tmp = pd.DataFrame({'k':k,'lds/sias':'sias','high/low':'high','pearson':pearson_sias_high,'r2score':r2_sias_high,'person_disc':discrete_pearson_sias_high,'cohen_disc':cohen_sias_high,'icc':icc_sias_high},index=np.arange(1))\n",
    "    df_results = pd.concat([df_results,df_tmp])\n",
    "\n",
    "    df_tmp = pd.DataFrame({'k':k,'lds/sias':'sias','high/low':'low','pearson':pearson_sias_low,'r2score':r2_sias_low,'person_disc':discrete_pearson_sias_low,'cohen_disc':cohen_sias_low,'icc':icc_sias_low},index=np.arange(1))\n",
    "    df_results = pd.concat([df_results,df_tmp])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Scatter correlation plot between LDS values and Pearson"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_correlation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for k in list(k_wind):\n",
    "    lds = df_correlation[df_correlation['k']==k]\n",
    "    lds_values = lds['lds'].values\n",
    "    pearson_values = lds['pearson'].values\n",
    "    lds_values = lds_values[:, np.newaxis]\n",
    "\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(lds_values, pearson_values)\n",
    "    predict = reg.predict(lds_values)\n",
    "\n",
    "    plt.title(k)\n",
    "    plt.plot(lds_values, predict, color='red')\n",
    "    plt.scatter(lds_values, pearson_values)\n",
    "    plt.xlabel('lds values')\n",
    "    plt.ylabel('pearson values')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Scatter correlation plot between SIAS values and Pearson"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for k in list(k_wind):\n",
    "    lds = df_correlation[df_correlation['k']==k]\n",
    "\n",
    "    sias_values = lds['sias_score'].values\n",
    "    sias_values = sias_values[:, np.newaxis]\n",
    "\n",
    "    reg_sias = LinearRegression()\n",
    "    reg_sias.fit(sias_values, pearson_values)\n",
    "    predict_sias = reg_sias.predict(sias_values)\n",
    "\n",
    "    plt.plot(sias_values, predict_sias, color='red')\n",
    "    plt.scatter(sias_values, pearson_values)\n",
    "    plt.xlabel('sias_values')\n",
    "    plt.ylabel('pearson values')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
